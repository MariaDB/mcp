2025-05-08 12:26:07,373 - config - INFO - Read-only mode: True
2025-05-08 12:26:07,373 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-08 12:26:07,385 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-08 12:26:07,385 - config - WARNING - Server running in READ-ONLY mode. Write operations are disabled.
2025-05-08 12:26:07,397 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-08 12:26:07,415 - config - INFO - Connection pool initialized successfully.
2025-05-08 12:26:07,419 - config - INFO - Registered MCP tools explicitly.
2025-05-08 12:26:07,420 - config - INFO - Starting MCP server via stdio...
2025-05-08 12:26:07,431 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-08 12:33:07,198 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 12:33:07,199 - config - INFO - TOOL START: list_databases called.
2025-05-08 12:33:07,200 - config - INFO - Executing query (DB: Chinook): SHOW DATABASES...
2025-05-08 12:33:07,233 - config - INFO - Query executed successfully, 8 rows returned.
2025-05-08 12:33:07,243 - config - INFO - TOOL END: list_databases completed. Databases found: 8.
2025-05-08 12:33:55,591 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 12:33:55,625 - config - INFO - TOOL START: list_tables called. database_name=chinook
2025-05-08 12:33:55,626 - config - INFO - Executing query (DB: chinook): SHOW TABLES...
2025-05-08 12:33:55,628 - config - INFO - Query executed successfully, 12 rows returned.
2025-05-08 12:33:55,628 - config - INFO - TOOL END: list_tables completed. Tables found: 12.
2025-05-08 12:35:47,956 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 12:35:47,959 - config - INFO - TOOL START: get_table_schema called. database_name=chinook, table_name=invoice
2025-05-08 12:35:47,960 - config - INFO - Executing query (DB: Chinook): DESCRIBE `chinook`.`invoice`...
2025-05-08 12:35:47,983 - config - INFO - Query executed successfully, 9 rows returned.
2025-05-08 12:35:47,983 - config - INFO - TOOL END: get_table_schema completed. Columns found: 9. Keys: ['InvoiceId', 'CustomerId', 'InvoiceDate', 'BillingAddress', 'BillingCity', 'BillingState', 'BillingCountry', 'BillingPostalCode', 'Total']
2025-05-08 12:37:17,471 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 12:37:17,471 - config - INFO - TOOL START: execute_sql called. database_name=chinook, sql_query=SELECT * FROM invoice LIMIT 5;, parameters=None
2025-05-08 12:37:17,472 - config - INFO - Executing query (DB: chinook): SELECT * FROM invoice LIMIT 5;...
2025-05-08 12:37:17,521 - config - INFO - Query executed successfully, 5 rows returned.
2025-05-08 12:37:17,522 - config - INFO - TOOL END: execute_sql completed. Rows returned: 5.
2025-05-08 12:41:00,914 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 12:41:00,914 - config - INFO - TOOL START: execute_sql called. database_name=chinook, sql_query=CREATE TABLE Orders (
    Order_Id INT PRIMARY KEY,
    Order_Items VARCHAR(255),
    Order_Qty INT,, parameters=None
2025-05-08 12:41:00,915 - config - WARNING - Blocked potentially non-read-only query in read-only mode: CREATE TABLE Orders (
    Order_Id INT PRIMARY KEY,
    Order_Items VARCHAR(255),
    Order_Qty INT,...
2025-05-08 12:41:00,915 - config - ERROR - TOOL ERROR: execute_sql failed for database_name=chinook, sql_query=CREATE TABLE Orders (
    Order_Id INT PRIMARY KEY,
    Order_Items VARCHAR(255),
    Order_Qty INT,, parameters=None: Operation forbidden: Server is in read-only mode.
Traceback (most recent call last):
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 227, in execute_sql
    results = await self._execute_query(sql_query, params=param_tuple, database=database_name)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 92, in _execute_query
    raise PermissionError("Operation forbidden: Server is in read-only mode.")
PermissionError: Operation forbidden: Server is in read-only mode.
2025-05-08 13:25:39,724 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 13:25:39,724 - config - INFO - TOOL START: execute_sql called. database_name=chinook, sql_query=CREATE TABLE Orders (
  Order_Id INT PRIMARY KEY,
  Order_Items VARCHAR(255),
  Order_Qty INT,
  Ord, parameters=None
2025-05-08 13:25:39,724 - config - WARNING - Blocked potentially non-read-only query in read-only mode: CREATE TABLE Orders (
  Order_Id INT PRIMARY KEY,
  Order_Items VARCHAR(255),
  Order_Qty INT,
  Ord...
2025-05-08 13:25:39,724 - config - ERROR - TOOL ERROR: execute_sql failed for database_name=chinook, sql_query=CREATE TABLE Orders (
  Order_Id INT PRIMARY KEY,
  Order_Items VARCHAR(255),
  Order_Qty INT,
  Ord, parameters=None: Operation forbidden: Server is in read-only mode.
Traceback (most recent call last):
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 227, in execute_sql
    results = await self._execute_query(sql_query, params=param_tuple, database=database_name)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 92, in _execute_query
    raise PermissionError("Operation forbidden: Server is in read-only mode.")
PermissionError: Operation forbidden: Server is in read-only mode.
2025-05-08 13:25:39,734 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 13:25:39,734 - config - INFO - TOOL START: execute_sql called. database_name=chinook, sql_query=CREATE TABLE Orders (
    Order_Id INT AUTO_INCREMENT PRIMARY KEY,
    Order_Items TEXT NULL,
    Or, parameters=None
2025-05-08 13:25:39,735 - config - WARNING - Blocked potentially non-read-only query in read-only mode: CREATE TABLE Orders (
    Order_Id INT AUTO_INCREMENT PRIMARY KEY,
    Order_Items TEXT NULL,
    Or...
2025-05-08 13:25:39,735 - config - ERROR - TOOL ERROR: execute_sql failed for database_name=chinook, sql_query=CREATE TABLE Orders (
    Order_Id INT AUTO_INCREMENT PRIMARY KEY,
    Order_Items TEXT NULL,
    Or, parameters=None: Operation forbidden: Server is in read-only mode.
Traceback (most recent call last):
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 227, in execute_sql
    results = await self._execute_query(sql_query, params=param_tuple, database=database_name)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 92, in _execute_query
    raise PermissionError("Operation forbidden: Server is in read-only mode.")
PermissionError: Operation forbidden: Server is in read-only mode.
2025-05-08 13:25:39,737 - config - CRITICAL - Server execution failed with an unexpected error: unhandled errors in a TaskGroup (2 sub-exceptions)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 273, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (2 sub-exceptions)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 79, in stdout_writer
    |     await stdout.flush()
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_core\_fileio.py", line 140, in flush
    |     return await to_thread.run_sync(self._fp.flush)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    |     return await get_async_backend().run_sync_in_worker_thread(
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2470, in run_sync_in_worker_thread
    |     return await future
    |            ^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    |     result = context.run(func, *args)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
    | OSError: [Errno 22] Invalid argument
    +---------------- 2 ----------------
    | Exception Group Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 86, in stdio_server
    |     yield read_stream, write_stream
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 812, in run_stdio_async
    |     await self._mcp_server.run(
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 483, in run
    |     async with AsyncExitStack() as stack:
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 745, in __aexit__
    |     raise exc_details[1]
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 728, in __aexit__
    |     cb_suppress = await cb(*exc_details)
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 209, in __aexit__
    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
    |     raise BaseExceptionGroup(
    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
    +-+---------------- 1 ----------------
      | Exception Group Traceback (most recent call last):
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 489, in run
      |     async with anyio.create_task_group() as tg:
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
      |     raise BaseExceptionGroup(
      | ExceptionGroup: unhandled errors in a TaskGroup (2 sub-exceptions)
      +-+---------------- 1 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\streams\memory.py", line 255, in send
        |     raise BrokenResourceError from None
        | anyio.BrokenResourceError
        +---------------- 2 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\streams\memory.py", line 255, in send
        |     raise BrokenResourceError from None
        | anyio.BrokenResourceError
        +------------------------------------
2025-05-08 13:25:39,894 - config - INFO - Closing database connection pool...
2025-05-08 13:25:39,894 - config - INFO - Database connection pool closed.
2025-05-08 13:25:39,903 - config - CRITICAL - Server failed to start or crashed: unhandled errors in a TaskGroup (2 sub-exceptions)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 305, in <module>
  |     anyio.run(
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_core\_eventloop.py", line 74, in run
  |     return async_backend.run(func, args, {}, backend_options)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2310, in run
  |     return runner.run(wrapper())
  |            ^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\runners.py", line 118, in run
  |     return self._loop.run_until_complete(task)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\base_events.py", line 653, in run_until_complete
  |     return future.result()
  |            ^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2298, in wrapper
  |     return await func(*args)
  |            ^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 273, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (2 sub-exceptions)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 79, in stdout_writer
    |     await stdout.flush()
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_core\_fileio.py", line 140, in flush
    |     return await to_thread.run_sync(self._fp.flush)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    |     return await get_async_backend().run_sync_in_worker_thread(
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2470, in run_sync_in_worker_thread
    |     return await future
    |            ^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    |     result = context.run(func, *args)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
    | OSError: [Errno 22] Invalid argument
    +---------------- 2 ----------------
    | Exception Group Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 86, in stdio_server
    |     yield read_stream, write_stream
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 812, in run_stdio_async
    |     await self._mcp_server.run(
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 483, in run
    |     async with AsyncExitStack() as stack:
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 745, in __aexit__
    |     raise exc_details[1]
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 728, in __aexit__
    |     cb_suppress = await cb(*exc_details)
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 209, in __aexit__
    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
    |     raise BaseExceptionGroup(
    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
    +-+---------------- 1 ----------------
      | Exception Group Traceback (most recent call last):
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 489, in run
      |     async with anyio.create_task_group() as tg:
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
      |     raise BaseExceptionGroup(
      | ExceptionGroup: unhandled errors in a TaskGroup (2 sub-exceptions)
      +-+---------------- 1 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\streams\memory.py", line 255, in send
        |     raise BrokenResourceError from None
        | anyio.BrokenResourceError
        +---------------- 2 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\streams\memory.py", line 255, in send
        |     raise BrokenResourceError from None
        | anyio.BrokenResourceError
        +------------------------------------
2025-05-08 13:25:39,939 - config - INFO - Server exiting with code 1.
2025-05-08 15:59:02,183 - config - INFO - Read-only mode: False
2025-05-08 15:59:02,183 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-08 15:59:02,192 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-08 15:59:02,201 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-08 15:59:02,215 - config - INFO - Connection pool initialized successfully.
2025-05-08 15:59:02,219 - config - INFO - Registered MCP tools explicitly.
2025-05-08 15:59:02,219 - config - INFO - Starting MCP server via stdio...
2025-05-08 15:59:02,242 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-08 15:59:02,242 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-08 15:59:02,248 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-08 15:59:02,264 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-08 16:00:37,919 - config - INFO - Read-only mode: False
2025-05-08 16:00:37,919 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-08 16:00:37,933 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-08 16:00:37,948 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-08 16:00:37,968 - config - INFO - Connection pool initialized successfully.
2025-05-08 16:00:37,971 - config - INFO - Registered MCP tools explicitly.
2025-05-08 16:00:37,972 - config - INFO - Starting MCP server via stdio...
2025-05-08 16:00:38,208 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-08 16:00:38,212 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-08 16:00:38,218 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-08 16:00:38,367 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-08 16:01:33,351 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 16:01:33,351 - config - INFO - TOOL START: create_database called for database: 'dummy_db'
2025-05-08 16:01:33,351 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-08 16:01:33,351 - config - INFO - Switching database context from 'chinook' to 'information_schema'
2025-05-08 16:01:33,366 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-08 16:01:33,366 - config - INFO - Executing query (DB: Chinook): CREATE DATABASE `dummy_db` CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;...
2025-05-08 16:01:33,366 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-08 16:01:33,366 - config - INFO - TOOL END: create_database. Database 'dummy_db' created successfully.
2025-05-08 16:02:19,758 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 16:02:19,758 - config - INFO - TOOL START: list_databases called.
2025-05-08 16:02:19,759 - config - INFO - Executing query (DB: Chinook): SHOW DATABASES...
2025-05-08 16:02:19,760 - config - INFO - Query executed successfully, 9 rows returned.
2025-05-08 16:02:19,761 - config - INFO - TOOL END: list_databases completed. Databases found: 9.
2025-05-08 16:52:58,622 - config - INFO - Read-only mode: False
2025-05-08 16:52:58,622 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-08 16:52:58,631 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-08 16:52:58,638 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-08 16:52:58,683 - config - INFO - Connection pool initialized successfully.
2025-05-08 16:52:58,688 - config - INFO - Registered MCP tools explicitly.
2025-05-08 16:52:58,688 - config - INFO - Starting MCP server via stdio...
2025-05-08 16:52:58,708 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-08 16:52:58,708 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-08 16:52:58,708 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-08 16:52:58,726 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-08 16:55:26,194 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 16:55:26,194 - config - INFO - TOOL START: create_vector_store called. DB: 'DUMMY_DB', Store: 'VDB_TBL', Embedding_Length: 1536, Distance_Requested: 'cosine'
2025-05-08 16:55:26,194 - config - INFO - Using SQL distance function: 'COSINE'.
2025-05-08 16:55:26,194 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-08 16:55:26,194 - config - INFO - Switching database context from 'chinook' to 'information_schema'
2025-05-08 16:55:26,194 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-08 16:55:26,194 - config - INFO - Database 'DUMMY_DB' does not exist. Attempting to create it.
2025-05-08 16:55:26,194 - config - INFO - TOOL START: create_database called for database: 'DUMMY_DB'
2025-05-08 16:55:26,194 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-08 16:55:26,194 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-08 16:55:26,194 - config - INFO - Executing query (DB: Chinook): CREATE DATABASE IF NOT EXISTS `DUMMY_DB`;...
2025-05-08 16:55:26,194 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-08 16:55:26,208 - config - INFO - TOOL END: create_database. Database 'DUMMY_DB' created successfully.
2025-05-08 16:55:26,208 - config - INFO - Executing query (DB: information_schema): SELECT TABLE_NAME FROM information_schema.TABLES WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s...
2025-05-08 16:55:26,211 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-08 16:55:26,211 - config - INFO - Executing query (DB: DUMMY_DB): 
        CREATE TABLE IF NOT EXISTS `VDB_TBL` (
            id BIGINT UNSIGNED PRIMARY KEY AUTO_INCR...
2025-05-08 16:55:26,213 - config - INFO - Switching database context from 'information_schema' to 'DUMMY_DB'
2025-05-08 16:55:26,254 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-08 16:55:26,255 - config - INFO - TOOL END: create_vector_store completed. Vector store 'VDB_TBL' created successfully in database 'DUMMY_DB' with COSINE distance.
2025-05-08 16:55:58,662 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 16:55:58,662 - config - INFO - TOOL START: get_table_schema called. database_name=DUMMY_DB, table_name=VDB_TBL
2025-05-08 16:55:58,662 - config - INFO - Executing query (DB: Chinook): DESCRIBE `DUMMY_DB`.`VDB_TBL`...
2025-05-08 16:55:58,692 - config - INFO - Query executed successfully, 4 rows returned.
2025-05-08 16:55:58,692 - config - INFO - TOOL END: get_table_schema completed. Columns found: 4. Keys: ['id', 'document', 'embedding', 'metadata']
2025-05-08 17:46:38,262 - config - INFO - Read-only mode: False
2025-05-08 17:46:38,262 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-08 17:46:38,270 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-08 17:46:38,276 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-08 17:46:38,290 - config - INFO - Connection pool initialized successfully.
2025-05-08 17:46:38,294 - config - INFO - Registered MCP tools explicitly.
2025-05-08 17:46:38,294 - config - INFO - Starting MCP server via stdio...
2025-05-08 17:46:38,315 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-08 17:46:38,315 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-08 17:46:38,315 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-08 17:46:38,331 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-08 17:48:24,726 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 17:48:24,726 - config - INFO - TOOL START: list_databases called.
2025-05-08 17:48:24,726 - config - INFO - Executing query (DB: Chinook): SHOW DATABASES...
2025-05-08 17:48:24,726 - config - INFO - Query executed successfully, 9 rows returned.
2025-05-08 17:48:24,726 - config - INFO - TOOL END: list_databases completed. Databases found: 9.
2025-05-08 17:48:31,506 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 17:48:31,506 - config - INFO - TOOL START: execute_sql called. database_name=chinook, sql_query=CREATE TABLE IF NOT EXISTS `dummy_tbl` (
    `col1` VARCHAR(255),
    `col2` VARCHAR(255),
    `col3, parameters=None
2025-05-08 17:48:31,506 - config - INFO - Executing query (DB: chinook): CREATE TABLE IF NOT EXISTS `dummy_tbl` (
    `col1` VARCHAR(255),
    `col2` VARCHAR(255),
    `col3...
2025-05-08 17:48:31,543 - asyncmy - WARNING - Table 'dummy_tbl' already exists
2025-05-08 17:48:31,543 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-08 17:48:31,543 - config - INFO - TOOL END: execute_sql completed. Rows returned: 0.
2025-05-08 17:48:35,839 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 17:48:35,839 - config - INFO - TOOL START: list_tables called. database_name=chinook
2025-05-08 17:48:35,840 - config - INFO - Executing query (DB: chinook): SHOW TABLES...
2025-05-08 17:48:35,841 - config - INFO - Query executed successfully, 12 rows returned.
2025-05-08 17:48:35,842 - config - INFO - TOOL END: list_tables completed. Tables found: 12.
2025-05-08 17:49:03,567 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 17:49:03,572 - config - INFO - TOOL START: list_tables called. database_name=chinook
2025-05-08 17:49:03,572 - config - INFO - Executing query (DB: chinook): SHOW TABLES...
2025-05-08 17:49:03,572 - config - INFO - Query executed successfully, 12 rows returned.
2025-05-08 17:49:03,572 - config - INFO - TOOL END: list_tables completed. Tables found: 12.
2025-05-08 17:52:50,199 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 17:52:50,200 - config - INFO - TOOL START: execute_sql called. database_name=chinook, sql_query=DROP TABLE IF EXISTS `dummy_tbl`;, parameters=None
2025-05-08 17:52:50,201 - config - INFO - Executing query (DB: chinook): DROP TABLE IF EXISTS `dummy_tbl`;...
2025-05-08 17:55:41,720 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 17:55:41,721 - config - INFO - TOOL START: execute_sql called. database_name=chinook, sql_query=DROP TABLE IF EXISTS `dummy_tbl`;, parameters=None
2025-05-08 17:55:41,721 - config - INFO - Executing query (DB: chinook): DROP TABLE IF EXISTS `dummy_tbl`;...
2025-05-08 17:56:38,320 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-08 17:56:38,324 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-08 17:57:20,399 - config - INFO - Closing database connection pool...
2025-05-08 17:57:20,401 - config - INFO - Database connection pool closed.
2025-05-08 17:57:20,404 - config - INFO - Server finished gracefully.
2025-05-08 17:57:20,406 - config - INFO - Server exiting with code 0.
2025-05-08 18:22:38,095 - config - INFO - Read-only mode: False
2025-05-08 18:22:38,096 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-08 18:22:38,105 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-08 18:22:38,111 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-08 18:22:38,125 - config - INFO - Connection pool initialized successfully.
2025-05-08 18:22:38,130 - config - INFO - Registered MCP tools explicitly.
2025-05-08 18:22:38,130 - config - INFO - Starting MCP server via stdio...
2025-05-08 18:22:38,151 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-08 18:22:38,151 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-08 18:22:38,151 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-08 18:22:38,168 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-08 19:50:02,286 - config - INFO - Read-only mode: False
2025-05-08 19:50:02,286 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-08 19:50:02,310 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-08 19:50:02,320 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-08 19:50:02,342 - config - INFO - Connection pool initialized successfully.
2025-05-08 19:50:02,349 - config - INFO - Registered MCP tools explicitly.
2025-05-08 19:50:02,350 - config - INFO - Starting MCP server via stdio...
2025-05-08 19:50:02,390 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-08 19:50:02,393 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-08 19:50:02,397 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-08 19:50:02,438 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-08 20:00:02,672 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-08 20:00:02,680 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-08 20:10:02,685 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-08 20:10:02,696 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-08 20:20:02,673 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-08 20:20:02,682 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-08 20:24:13,910 - config - INFO - Read-only mode: False
2025-05-08 20:24:13,911 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-08 20:24:13,972 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-08 20:24:13,996 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-08 20:24:14,109 - config - INFO - Connection pool initialized successfully.
2025-05-08 20:24:14,124 - config - INFO - Registered MCP tools explicitly.
2025-05-08 20:24:14,125 - config - INFO - Starting MCP server via stdio...
2025-05-08 20:24:14,189 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-08 20:24:14,700 - config - INFO - Read-only mode: False
2025-05-08 20:24:14,701 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-08 20:24:14,893 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-08 20:24:14,959 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-08 20:24:15,003 - config - INFO - Connection pool initialized successfully.
2025-05-08 20:24:15,020 - config - INFO - Registered MCP tools explicitly.
2025-05-08 20:24:15,023 - config - INFO - Starting MCP server via stdio...
2025-05-08 20:24:15,055 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-08 20:24:26,733 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 20:24:26,734 - config - INFO - TOOL START: list_databases called.
2025-05-08 20:24:26,735 - config - INFO - Executing query (DB: Chinook): SHOW DATABASES...
2025-05-08 20:24:26,738 - config - INFO - Query executed successfully, 9 rows returned.
2025-05-08 20:24:26,739 - config - INFO - TOOL END: list_databases completed. Databases found: 9.
2025-05-08 20:24:32,103 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 20:24:32,104 - config - INFO - TOOL START: list_tables called. database_name=chinook
2025-05-08 20:24:32,105 - config - INFO - Executing query (DB: chinook): SHOW TABLES...
2025-05-08 20:24:32,110 - config - INFO - Query executed successfully, 12 rows returned.
2025-05-08 20:24:32,110 - config - INFO - TOOL END: list_tables completed. Tables found: 12.
2025-05-08 20:24:37,414 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 20:24:37,415 - config - INFO - TOOL START: get_table_schema called. database_name=chinook, table_name=album
2025-05-08 20:24:37,415 - config - INFO - Executing query (DB: Chinook): DESCRIBE `chinook`.`album`...
2025-05-08 20:24:37,459 - config - INFO - Query executed successfully, 3 rows returned.
2025-05-08 20:24:37,461 - config - INFO - TOOL END: get_table_schema completed. Columns found: 3. Keys: ['AlbumId', 'Title', 'ArtistId']
2025-05-08 20:24:42,643 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 20:24:42,644 - config - INFO - TOOL START: get_table_schema called. database_name=chinook, table_name=artist
2025-05-08 20:24:42,645 - config - INFO - Executing query (DB: Chinook): DESCRIBE `chinook`.`artist`...
2025-05-08 20:24:42,691 - config - INFO - Query executed successfully, 2 rows returned.
2025-05-08 20:24:42,693 - config - INFO - TOOL END: get_table_schema completed. Columns found: 2. Keys: ['ArtistId', 'Name']
2025-05-08 20:24:45,784 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 20:24:45,785 - config - INFO - TOOL START: get_table_schema called. database_name=chinook, table_name=customer
2025-05-08 20:24:45,786 - config - INFO - Executing query (DB: Chinook): DESCRIBE `chinook`.`customer`...
2025-05-08 20:24:45,813 - config - INFO - Query executed successfully, 13 rows returned.
2025-05-08 20:24:45,813 - config - INFO - TOOL END: get_table_schema completed. Columns found: 13. Keys: ['CustomerId', 'FirstName', 'LastName', 'Company', 'Address', 'City', 'State', 'Country', 'PostalCode', 'Phone', 'Fax', 'Email', 'SupportRepId']
2025-05-08 20:24:49,074 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 20:24:49,076 - config - INFO - TOOL START: get_table_schema called. database_name=chinook, table_name=dummy_tbl
2025-05-08 20:24:49,076 - config - INFO - Executing query (DB: Chinook): DESCRIBE `chinook`.`dummy_tbl`...
2025-05-08 20:24:49,112 - config - INFO - Query executed successfully, 4 rows returned.
2025-05-08 20:24:49,113 - config - INFO - TOOL END: get_table_schema completed. Columns found: 4. Keys: ['id', 'name', 'value', 'created_at']
2025-05-08 20:24:51,549 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-08 21:15:48,268 - config - INFO - TOOL START: get_table_schema called. database_name=chinook, table_name=employee
2025-05-08 21:15:48,269 - config - INFO - Executing query (DB: Chinook): DESCRIBE `chinook`.`employee`...
2025-05-08 21:15:48,293 - config - INFO - Query executed successfully, 15 rows returned.
2025-05-08 21:15:48,293 - config - INFO - TOOL END: get_table_schema completed. Columns found: 15. Keys: ['EmployeeId', 'LastName', 'FirstName', 'Title', 'ReportsTo', 'BirthDate', 'HireDate', 'Address', 'City', 'State', 'Country', 'PostalCode', 'Phone', 'Fax', 'Email']
2025-05-08 21:15:48,298 - config - CRITICAL - Server execution failed with an unexpected error: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 514, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Exception Group Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 86, in stdio_server
    |     yield read_stream, write_stream
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 812, in run_stdio_async
    |     await self._mcp_server.run(
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 483, in run
    |     async with AsyncExitStack() as stack:
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 745, in __aexit__
    |     raise exc_details[1]
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 728, in __aexit__
    |     cb_suppress = await cb(*exc_details)
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 209, in __aexit__
    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
    |     raise BaseExceptionGroup(
    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
    +-+---------------- 1 ----------------
      | Exception Group Traceback (most recent call last):
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 489, in run
      |     async with anyio.create_task_group() as tg:
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
      |     raise BaseExceptionGroup(
      | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
      +-+---------------- 1 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\streams\memory.py", line 242, in send
        |     self.send_nowait(item)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\streams\memory.py", line 211, in send_nowait
        |     raise ClosedResourceError
        | anyio.ClosedResourceError
        +------------------------------------
2025-05-08 21:15:48,485 - config - INFO - Closing database connection pool...
2025-05-08 21:15:48,487 - config - INFO - Database connection pool closed.
2025-05-08 21:15:48,489 - config - CRITICAL - Server failed to start or crashed: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 546, in <module>
  |     anyio.run(
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_core\_eventloop.py", line 74, in run
  |     return async_backend.run(func, args, {}, backend_options)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2310, in run
  |     return runner.run(wrapper())
  |            ^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\runners.py", line 118, in run
  |     return self._loop.run_until_complete(task)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\base_events.py", line 653, in run_until_complete
  |     return future.result()
  |            ^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2298, in wrapper
  |     return await func(*args)
  |            ^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 514, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Exception Group Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 86, in stdio_server
    |     yield read_stream, write_stream
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 812, in run_stdio_async
    |     await self._mcp_server.run(
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 483, in run
    |     async with AsyncExitStack() as stack:
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 745, in __aexit__
    |     raise exc_details[1]
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 728, in __aexit__
    |     cb_suppress = await cb(*exc_details)
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 209, in __aexit__
    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
    |     raise BaseExceptionGroup(
    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
    +-+---------------- 1 ----------------
      | Exception Group Traceback (most recent call last):
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 489, in run
      |     async with anyio.create_task_group() as tg:
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
      |     raise BaseExceptionGroup(
      | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
      +-+---------------- 1 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\streams\memory.py", line 242, in send
        |     self.send_nowait(item)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\streams\memory.py", line 211, in send_nowait
        |     raise ClosedResourceError
        | anyio.ClosedResourceError
        +------------------------------------
2025-05-08 21:15:48,536 - config - INFO - Server exiting with code 1.
2025-05-09 07:43:57,395 - config - INFO - Read-only mode: False
2025-05-09 07:43:57,400 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-09 07:43:57,458 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-09 07:43:57,480 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-09 07:43:57,515 - config - INFO - Connection pool initialized successfully.
2025-05-09 07:43:57,528 - config - INFO - Registered MCP tools explicitly.
2025-05-09 07:43:57,529 - config - INFO - Starting MCP server via stdio...
2025-05-09 07:43:57,591 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-09 07:43:57,595 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-09 07:43:57,599 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-09 07:43:57,638 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-09 11:11:13,977 - config - INFO - Read-only mode: False
2025-05-09 11:11:13,977 - config - INFO - Read-only mode: False
2025-05-09 11:11:13,977 - config - INFO - Read-only mode: False
2025-05-09 11:11:13,977 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-09 11:11:13,977 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-09 11:11:13,977 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-09 11:11:13,994 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-09 11:11:13,994 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-09 11:11:13,994 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-09 11:11:13,994 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-09 11:11:13,994 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-09 11:11:13,994 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-09 11:11:13,994 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-09 11:11:14,010 - config - INFO - Connection pool initialized successfully.
2025-05-09 11:11:14,010 - config - INFO - Connection pool initialized successfully.
2025-05-09 11:11:14,026 - config - INFO - Registered MCP tools explicitly.
2025-05-09 11:11:14,026 - config - INFO - Registered MCP tools explicitly.
2025-05-09 11:11:14,026 - config - INFO - Registered MCP tools explicitly.
2025-05-09 11:11:14,026 - config - INFO - Registered MCP tools explicitly.
2025-05-09 11:11:14,026 - config - INFO - Starting MCP server via stdio...
2025-05-09 11:11:14,026 - config - INFO - Starting MCP server via stdio...
2025-05-09 11:11:14,026 - config - INFO - Starting MCP server via stdio...
2025-05-09 11:11:14,026 - config - INFO - Starting MCP server via stdio...
2025-05-09 11:11:14,044 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-09 11:11:14,044 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-09 11:11:14,044 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-09 11:11:14,044 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-09 11:11:14,044 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-09 11:11:14,044 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-09 11:11:14,044 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-09 11:11:14,044 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-09 11:11:19,007 - config - INFO - Read-only mode: False
2025-05-09 11:11:19,007 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-09 11:11:19,023 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-09 11:11:19,023 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-09 11:11:19,045 - config - INFO - Connection pool initialized successfully.
2025-05-09 11:11:19,045 - config - INFO - Registered MCP tools explicitly.
2025-05-09 11:11:19,045 - config - INFO - Starting MCP server via stdio...
2025-05-09 11:11:19,059 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-09 11:14:17,347 - config - INFO - Read-only mode: False
2025-05-09 11:14:17,347 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-09 11:14:17,356 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-09 11:14:17,371 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-09 11:14:17,387 - config - INFO - Connection pool initialized successfully.
2025-05-09 11:14:17,392 - config - INFO - Registered MCP tools explicitly.
2025-05-09 11:14:17,392 - config - INFO - Starting MCP server via stdio...
2025-05-09 11:14:17,414 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-09 11:14:17,415 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-09 11:14:18,296 - config - INFO - Read-only mode: False
2025-05-09 11:14:18,297 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-09 11:14:18,308 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-09 11:14:18,315 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-09 11:14:18,332 - config - INFO - Connection pool initialized successfully.
2025-05-09 11:14:18,337 - config - INFO - Registered MCP tools explicitly.
2025-05-09 11:14:18,338 - config - INFO - Starting MCP server via stdio...
2025-05-09 11:14:18,348 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-09 11:15:11,886 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-09 11:15:11,886 - config - INFO - TOOL START: list_databases called.
2025-05-09 11:15:11,886 - config - INFO - Executing query (DB: Chinook): SHOW DATABASES...
2025-05-09 11:15:11,899 - config - INFO - Query executed successfully, 9 rows returned.
2025-05-09 11:15:11,900 - config - INFO - TOOL END: list_databases completed. Databases found: 9.
2025-05-09 11:15:52,665 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-09 11:15:52,714 - config - INFO - TOOL START: list_tables called. database_name=chinook
2025-05-09 11:15:52,714 - config - INFO - Executing query (DB: chinook): SHOW TABLES...
2025-05-09 11:15:52,714 - config - INFO - Query executed successfully, 12 rows returned.
2025-05-09 11:15:52,714 - config - INFO - TOOL END: list_tables completed. Tables found: 12.
2025-05-09 11:16:27,097 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-09 11:16:27,098 - config - INFO - TOOL START: execute_sql called. database_name=chinook, sql_query=SELECT * FROM track LIMIT 5;, parameters=None
2025-05-09 11:16:27,099 - config - INFO - Executing query (DB: chinook): SELECT * FROM track LIMIT 5;...
2025-05-09 11:16:27,119 - config - INFO - Query executed successfully, 5 rows returned.
2025-05-09 11:16:27,119 - config - INFO - TOOL END: execute_sql completed. Rows returned: 5.
2025-05-09 11:17:13,016 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-09 11:17:13,017 - config - INFO - TOOL START: get_table_schema called. database_name=chinook, table_name=track
2025-05-09 11:17:13,018 - config - INFO - Executing query (DB: Chinook): DESCRIBE `chinook`.`track`...
2025-05-09 11:17:13,073 - config - INFO - Query executed successfully, 9 rows returned.
2025-05-09 11:17:13,073 - config - INFO - TOOL END: get_table_schema completed. Columns found: 9. Keys: ['TrackId', 'Name', 'AlbumId', 'MediaTypeId', 'GenreId', 'Composer', 'Milliseconds', 'Bytes', 'UnitPrice']
2025-05-09 11:17:59,261 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-09 11:17:59,262 - config - INFO - TOOL START: execute_sql called. database_name=chinook, sql_query=SELECT * FROM dummy_tbl LIMIT 5;, parameters=None
2025-05-09 11:17:59,262 - config - INFO - Executing query (DB: chinook): SELECT * FROM dummy_tbl LIMIT 5;...
2025-05-09 11:17:59,297 - config - INFO - Query executed successfully, 5 rows returned.
2025-05-09 11:17:59,298 - config - INFO - TOOL END: execute_sql completed. Rows returned: 5.
2025-05-09 11:18:30,427 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-09 11:18:30,428 - config - INFO - TOOL START: execute_sql called. database_name=chinook, sql_query=DROP TABLE dummy_tbl;, parameters=None
2025-05-09 11:18:30,429 - config - INFO - Executing query (DB: chinook): DROP TABLE dummy_tbl;...
2025-05-09 11:18:30,506 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-09 11:18:30,506 - config - INFO - TOOL END: execute_sql completed. Rows returned: 0.
2025-05-09 11:19:02,802 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-09 11:19:02,802 - config - INFO - TOOL START: execute_sql called. database_name=chinook, sql_query=DROP TABLE dummy_tbl;, parameters=None
2025-05-09 11:19:02,803 - config - INFO - Executing query (DB: chinook): DROP TABLE dummy_tbl;...
2025-05-09 11:19:02,847 - config - ERROR - Database error executing query (Connection: acquired): (1051, "Unknown table 'chinook.dummy_tbl'")
Traceback (most recent call last):
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 113, in _execute_query
    await cursor.execute(sql, params or ())
  File "asyncmy\\cursors.pyx", line 179, in execute
  File "asyncmy\\cursors.pyx", line 364, in _query
  File "asyncmy\\connection.pyx", line 496, in query
  File "asyncmy\\connection.pyx", line 684, in _read_query_result
  File "asyncmy\\connection.pyx", line 1071, in read
  File "asyncmy\\connection.pyx", line 646, in read_packet
  File "asyncmy\\protocol.pyx", line 190, in asyncmy.protocol.MysqlPacket.raise_for_error
  File "asyncmy\\protocol.pyx", line 194, in asyncmy.protocol.MysqlPacket.raise_for_error
  File "asyncmy\\errors.pyx", line 128, in asyncmy.errors.raise_mysql_exception
  File "asyncmy\\errors.pyx", line 137, in asyncmy.errors.raise_mysql_exception
asyncmy.errors.OperationalError: (1051, "Unknown table 'chinook.dummy_tbl'")
2025-05-09 11:19:02,863 - config - ERROR - TOOL ERROR: execute_sql failed for database_name=chinook, sql_query=DROP TABLE dummy_tbl;, parameters=None: Database error: (1051, "Unknown table 'chinook.dummy_tbl'")
Traceback (most recent call last):
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 113, in _execute_query
    await cursor.execute(sql, params or ())
  File "asyncmy\\cursors.pyx", line 179, in execute
  File "asyncmy\\cursors.pyx", line 364, in _query
  File "asyncmy\\connection.pyx", line 496, in query
  File "asyncmy\\connection.pyx", line 684, in _read_query_result
  File "asyncmy\\connection.pyx", line 1071, in read
  File "asyncmy\\connection.pyx", line 646, in read_packet
  File "asyncmy\\protocol.pyx", line 190, in asyncmy.protocol.MysqlPacket.raise_for_error
  File "asyncmy\\protocol.pyx", line 194, in asyncmy.protocol.MysqlPacket.raise_for_error
  File "asyncmy\\errors.pyx", line 128, in asyncmy.errors.raise_mysql_exception
  File "asyncmy\\errors.pyx", line 137, in asyncmy.errors.raise_mysql_exception
asyncmy.errors.OperationalError: (1051, "Unknown table 'chinook.dummy_tbl'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 254, in execute_sql
    results = await self._execute_query(sql_query, params=param_tuple, database=database_name)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 121, in _execute_query
    raise RuntimeError(f"Database error: {e}") from e
RuntimeError: Database error: (1051, "Unknown table 'chinook.dummy_tbl'")
2025-05-09 11:19:35,009 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-09 11:19:35,010 - config - INFO - TOOL START: list_tables called. database_name=chinook
2025-05-09 11:19:35,010 - config - INFO - Executing query (DB: chinook): SHOW TABLES...
2025-05-09 11:19:35,012 - config - INFO - Query executed successfully, 11 rows returned.
2025-05-09 11:19:35,013 - config - INFO - TOOL END: list_tables completed. Tables found: 11.
2025-05-12 07:17:31,837 - config - INFO - Read-only mode: False
2025-05-12 07:17:31,842 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-12 07:17:31,870 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-12 07:17:31,893 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-12 07:17:32,064 - config - INFO - Connection pool initialized successfully.
2025-05-12 07:17:32,075 - config - INFO - Registered MCP tools explicitly.
2025-05-12 07:17:32,076 - config - INFO - Starting MCP server via stdio...
2025-05-12 07:17:32,130 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 07:17:32,142 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 07:17:32,198 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-12 07:17:32,239 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-12 19:17:39,730 - config - INFO - Selected Embedding Provider: openai" # options: "openai" or "gemini
2025-05-12 19:17:39,730 - config - ERROR - Invalid EMBEDDING_PROVIDER specified: 'openai" # options: "openai" or "gemini'. Use 'openai' or 'gemini'.
2025-05-12 19:23:49,951 - config - INFO - Selected Embedding Provider: openai" # options: "openai" or "gemini
2025-05-12 19:23:49,952 - config - ERROR - Invalid EMBEDDING_PROVIDER specified: 'openai" # options: "openai" or "gemini'. Use 'openai' or 'gemini'.
2025-05-12 19:24:58,993 - __main__ - INFO - Selected Embedding Provider: openai" # options: "openai" or "gemini
2025-05-12 19:24:58,994 - __main__ - ERROR - Invalid EMBEDDING_PROVIDER specified: 'openai" # options: "openai" or "gemini'. Use 'openai' or 'gemini'.
2025-05-12 19:26:59,111 - __main__ - INFO - Selected Embedding Provider: openai" # options: "openai" or "gemini
2025-05-12 19:26:59,111 - __main__ - ERROR - Invalid EMBEDDING_PROVIDER specified: 'openai" # options: "openai" or "gemini'. Use 'openai' or 'gemini'.
2025-05-12 19:27:42,535 - config - INFO - Selected Embedding Provider: openai" # options: "openai" or "gemini
2025-05-12 19:27:42,535 - config - ERROR - Invalid EMBEDDING_PROVIDER specified: 'openai" # options: "openai" or "gemini'. Use 'openai' or 'gemini'.
2025-05-12 19:29:12,098 - config - INFO - Selected Embedding Provider: openai
2025-05-12 19:29:12,098 - config - INFO - Read-only mode: False
2025-05-12 19:29:12,098 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-12 19:29:58,411 - config - INFO - Selected Embedding Provider: openai
2025-05-12 19:29:58,411 - config - INFO - Read-only mode: False
2025-05-12 19:29:58,411 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-12 19:52:06,758 - config - INFO - Selected Embedding Provider: openai
2025-05-12 19:52:06,758 - config - INFO - Read-only mode: False
2025-05-12 19:52:06,758 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-12 19:52:06,768 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-12 19:52:06,783 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-12 19:52:06,804 - config - INFO - Connection pool initialized successfully.
2025-05-12 19:52:06,807 - config - INFO - Registered MCP tools explicitly.
2025-05-12 19:52:06,807 - config - INFO - Starting MCP server via stdio...
2025-05-12 19:52:06,818 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 19:53:34,593 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 19:53:34,594 - config - INFO - TOOL START: list_vector_stores called for database: 'DUMMY_DB'
2025-05-12 19:53:34,594 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 19:53:34,600 - config - INFO - Switching database context from 'chinook' to 'information_schema'
2025-05-12 19:53:34,605 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 19:53:34,606 - config - INFO - Executing query (DB: information_schema): 
        SELECT DISTINCT T1.TABLE_NAME
        FROM information_schema.COLUMNS AS T1
        INNER J...
2025-05-12 19:53:34,874 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 19:53:34,875 - config - INFO - Found 1 vector store(s) in database 'DUMMY_DB': ['vdb_tbl']
2025-05-12 19:53:34,875 - config - INFO - TOOL END: list_vector_stores completed for database 'DUMMY_DB'.
2025-05-12 19:53:39,514 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 19:53:39,515 - config - INFO - TOOL START: delete_vector_store called for: 'DUMMY_DB.vdb_tbl'
2025-05-12 19:53:39,516 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 19:53:39,518 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 19:53:39,519 - config - INFO - Executing query (DB: information_schema): SELECT TABLE_NAME FROM information_schema.TABLES WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s...
2025-05-12 19:53:39,520 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 19:53:39,521 - config - INFO - Executing query (DB: information_schema): 
        SELECT COUNT(T1.TABLE_NAME) AS vector_store_count
        FROM information_schema.COLUMNS A...
2025-05-12 19:53:39,765 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 19:53:39,767 - config - INFO - Executing query (DB: DUMMY_DB): DROP TABLE IF EXISTS `vdb_tbl`;...
2025-05-12 19:53:39,767 - config - INFO - Switching database context from 'information_schema' to 'DUMMY_DB'
2025-05-12 19:53:39,801 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-12 19:53:39,801 - config - INFO - TOOL END: delete_vector_store. Vector store 'vdb_tbl' deleted successfully from database 'DUMMY_DB'.
2025-05-12 19:53:44,190 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 19:53:44,193 - config - INFO - TOOL START: create_database called for database: 'DUMMY_DB'
2025-05-12 19:53:44,194 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 19:53:44,195 - config - INFO - Switching database context from 'dummy_db' to 'information_schema'
2025-05-12 19:53:44,197 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 19:53:44,198 - config - INFO - TOOL END: create_database. Database 'DUMMY_DB' already exists.
2025-05-12 20:00:32,753 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 20:00:32,754 - config - INFO - TOOL START: list_tables called. database_name=DUMMY_DB
2025-05-12 20:00:32,754 - config - INFO - Executing query (DB: DUMMY_DB): SHOW TABLES...
2025-05-12 20:00:32,756 - config - INFO - Switching database context from 'information_schema' to 'DUMMY_DB'
2025-05-12 20:00:32,758 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 20:00:32,759 - config - INFO - TOOL START: list_vector_stores called for database: 'DUMMY_DB'
2025-05-12 20:00:32,759 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 20:00:32,761 - config - CRITICAL - Server execution failed with an unexpected error: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 639, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 79, in stdout_writer
    |     await stdout.flush()
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_core\_fileio.py", line 140, in flush
    |     return await to_thread.run_sync(self._fp.flush)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    |     return await get_async_backend().run_sync_in_worker_thread(
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2470, in run_sync_in_worker_thread
    |     return await future
    |            ^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    |     result = context.run(func, *args)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
    | OSError: [Errno 22] Invalid argument
    +------------------------------------
2025-05-12 20:00:32,915 - config - INFO - Closing database connection pool...
2025-05-12 20:00:32,915 - config - INFO - Database connection pool closed.
2025-05-12 20:00:32,917 - config - CRITICAL - Server failed to start or crashed: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 671, in <module>
  |     anyio.run(
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_core\_eventloop.py", line 74, in run
  |     return async_backend.run(func, args, {}, backend_options)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2310, in run
  |     return runner.run(wrapper())
  |            ^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\runners.py", line 118, in run
  |     return self._loop.run_until_complete(task)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\base_events.py", line 653, in run_until_complete
  |     return future.result()
  |            ^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2298, in wrapper
  |     return await func(*args)
  |            ^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 639, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 79, in stdout_writer
    |     await stdout.flush()
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_core\_fileio.py", line 140, in flush
    |     return await to_thread.run_sync(self._fp.flush)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    |     return await get_async_backend().run_sync_in_worker_thread(
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2470, in run_sync_in_worker_thread
    |     return await future
    |            ^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    |     result = context.run(func, *args)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
    | OSError: [Errno 22] Invalid argument
    +------------------------------------
2025-05-12 20:00:32,961 - config - INFO - Server exiting with code 1.
2025-05-12 20:33:39,335 - config - INFO - Selected Embedding Provider: openai
2025-05-12 20:33:39,335 - config - INFO - Read-only mode: False
2025-05-12 20:33:39,336 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-12 20:33:39,345 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-12 20:33:39,351 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-12 20:33:39,365 - config - INFO - Connection pool initialized successfully.
2025-05-12 20:33:39,371 - config - INFO - Registered MCP tools explicitly.
2025-05-12 20:33:39,372 - config - INFO - Starting MCP server via stdio...
2025-05-12 20:33:39,380 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 20:50:12,371 - config - INFO - Selected Embedding Provider: openai
2025-05-12 20:50:12,371 - config - INFO - Selected Embedding Provider: openai
2025-05-12 20:50:12,371 - config - INFO - Read-only mode: False
2025-05-12 20:50:12,371 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-12 20:50:12,371 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-12 20:50:12,374 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-12 20:50:12,389 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-12 20:50:12,389 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-12 20:50:12,407 - config - INFO - Connection pool initialized successfully.
2025-05-12 20:50:12,412 - config - INFO - Registered MCP tools explicitly.
2025-05-12 20:50:12,413 - config - INFO - Starting MCP server via stdio...
2025-05-12 20:50:12,436 - config - INFO - Connection pool initialized successfully.
2025-05-12 20:50:12,438 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 20:50:12,438 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 20:50:12,438 - config - INFO - Registered MCP tools explicitly.
2025-05-12 20:50:12,438 - config - INFO - Starting MCP server via stdio...
2025-05-12 20:50:12,453 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 20:50:12,456 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 20:50:26,309 - config - INFO - Selected Embedding Provider: openai
2025-05-12 20:50:26,309 - config - INFO - Read-only mode: False
2025-05-12 20:50:26,309 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-12 20:50:26,319 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-12 20:50:26,335 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-12 20:50:26,349 - config - INFO - Connection pool initialized successfully.
2025-05-12 20:50:26,355 - config - INFO - Registered MCP tools explicitly.
2025-05-12 20:50:26,355 - config - INFO - Starting MCP server via stdio...
2025-05-12 20:50:26,355 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 20:50:27,352 - config - INFO - Selected Embedding Provider: openai
2025-05-12 20:50:27,352 - config - INFO - Read-only mode: False
2025-05-12 20:50:27,353 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-12 20:50:27,362 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-12 20:50:27,368 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-12 20:50:27,383 - config - INFO - Connection pool initialized successfully.
2025-05-12 20:50:27,388 - config - INFO - Registered MCP tools explicitly.
2025-05-12 20:50:27,388 - config - INFO - Starting MCP server via stdio...
2025-05-12 20:50:27,397 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 20:51:31,936 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 20:51:31,936 - config - INFO - TOOL START: create_database called for database: 'DUMMY_DB'
2025-05-12 20:51:31,936 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 20:51:31,936 - config - INFO - Switching database context from 'chinook' to 'information_schema'
2025-05-12 20:51:31,936 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-12 20:51:31,936 - config - INFO - Executing query (DB: Chinook): CREATE DATABASE IF NOT EXISTS `DUMMY_DB`;...
2025-05-12 20:51:31,936 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-12 20:51:31,936 - config - INFO - TOOL END: create_database. Database 'DUMMY_DB' created successfully.
2025-05-12 20:52:43,203 - config - INFO - Selected Embedding Provider: openai
2025-05-12 20:52:43,203 - config - INFO - Read-only mode: False
2025-05-12 20:52:43,204 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-12 20:52:43,213 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-12 20:52:43,222 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-12 20:52:43,238 - config - INFO - Connection pool initialized successfully.
2025-05-12 20:52:43,244 - config - INFO - Registered MCP tools explicitly.
2025-05-12 20:52:43,244 - config - INFO - Starting MCP server via stdio...
2025-05-12 20:52:43,252 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 20:52:43,796 - config - INFO - Selected Embedding Provider: openai
2025-05-12 20:52:43,796 - config - INFO - Read-only mode: False
2025-05-12 20:52:43,796 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-12 20:52:43,810 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-12 20:52:43,812 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-12 20:52:43,833 - config - INFO - Connection pool initialized successfully.
2025-05-12 20:52:43,835 - config - INFO - Registered MCP tools explicitly.
2025-05-12 20:52:43,835 - config - INFO - Starting MCP server via stdio...
2025-05-12 20:52:43,850 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 20:57:16,037 - config - INFO - Selected Embedding Provider: openai
2025-05-12 20:57:16,037 - config - INFO - Read-only mode: False
2025-05-12 20:57:16,037 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-12 20:57:16,054 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-12 20:57:16,054 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-12 20:57:16,070 - config - INFO - Connection pool initialized successfully.
2025-05-12 20:57:16,070 - config - INFO - Registered MCP tools explicitly.
2025-05-12 20:57:16,070 - config - INFO - Starting MCP server via stdio...
2025-05-12 20:57:16,089 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 21:01:21,552 - config - INFO - Selected Embedding Provider: openai
2025-05-12 21:01:21,553 - config - INFO - Read-only mode: False
2025-05-12 21:01:21,553 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-12 21:01:21,571 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-12 21:01:21,585 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-12 21:01:21,606 - config - INFO - Connection pool initialized successfully.
2025-05-12 21:01:21,615 - config - INFO - Registered MCP tools explicitly.
2025-05-12 21:01:21,616 - config - INFO - Starting MCP server via stdio...
2025-05-12 21:01:21,628 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 21:15:52,881 - config - INFO - Selected Embedding Provider: openai
2025-05-12 21:15:52,881 - config - INFO - Selected Embedding Provider: openai
2025-05-12 21:15:52,883 - config - INFO - Read-only mode: False
2025-05-12 21:15:52,884 - config - INFO - Read-only mode: False
to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-12 21:15:52,884 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-12 21:15:54,078 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-12 21:15:54,085 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-12 21:15:54,834 - config - INFO - Selected Embedding Provider: openai
2025-05-12 21:15:54,834 - config - INFO - Read-only mode: False
2025-05-12 21:15:54,834 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-12 21:15:55,900 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-12 21:15:56,802 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-12 21:15:56,817 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-12 21:15:56,824 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-12 21:15:56,836 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-12 21:15:56,836 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-12 21:15:56,858 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-12 21:15:56,858 - config - INFO - Connection pool initialized successfully.
2025-05-12 21:15:56,872 - config - INFO - Registered MCP tools explicitly.
2025-05-12 21:15:56,875 - config - INFO - Starting MCP server via stdio...
2025-05-12 21:15:56,879 - config - INFO - Connection pool initialized successfully.
2025-05-12 21:15:56,886 - config - INFO - Registered MCP tools explicitly.
2025-05-12 21:15:56,886 - config - INFO - Starting MCP server via stdio...
2025-05-12 21:15:57,118 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-12 21:15:57,134 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-12 21:15:57,151 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-12 21:15:57,185 - config - INFO - Connection pool initialized successfully.
2025-05-12 21:15:57,185 - config - INFO - Registered MCP tools explicitly.
2025-05-12 21:15:57,185 - config - INFO - Starting MCP server via stdio...
2025-05-12 21:15:57,234 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 21:15:57,234 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 21:15:57,252 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-12 21:16:26,424 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 21:16:26,425 - config - INFO - TOOL START: list_databases called.
2025-05-12 21:16:26,425 - config - INFO - Executing query (DB: Chinook): SHOW DATABASES...
2025-05-12 21:16:26,430 - config - INFO - Query executed successfully, 9 rows returned.
2025-05-12 21:16:26,431 - config - INFO - TOOL END: list_databases completed. Databases found: 9.
2025-05-12 21:17:05,721 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 21:17:05,722 - config - INFO - TOOL START: create_vector_store called. DB: 'dummy_db', Store: 'VDB_tbl', Model: 'None', Embedding_Length: 1536, Distance_Requested: 'None'
2025-05-12 21:17:05,722 - config - INFO - Distance function not provided, defaulting to 'COSINE'.
2025-05-12 21:17:05,723 - config - INFO - Using SQL distance function: 'COSINE'.
2025-05-12 21:17:05,723 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 21:17:05,724 - config - INFO - Switching database context from 'chinook' to 'information_schema'
2025-05-12 21:17:05,726 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 21:17:05,727 - config - INFO - Executing query (DB: information_schema): SELECT TABLE_NAME FROM information_schema.TABLES WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s...
2025-05-12 21:17:05,731 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-12 21:17:05,731 - config - INFO - Executing query (DB: dummy_db): 
        CREATE TABLE IF NOT EXISTS `VDB_tbl` (
            id VARCHAR(36) NOT NULL DEFAULT UUID_v7(...
2025-05-12 21:17:05,731 - config - INFO - Switching database context from 'information_schema' to 'dummy_db'
2025-05-12 21:17:05,781 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-12 21:17:05,782 - config - INFO - TOOL END: create_vector_store completed. Vector store 'VDB_tbl' created successfully in database 'dummy_db' with COSINE distance.
2025-05-12 21:18:12,463 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 21:18:12,463 - config - INFO - TOOL START: delete_vector_store called for: 'dummy_db.VDB_tbl'
2025-05-12 21:18:12,463 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 21:18:12,463 - config - INFO - Switching database context from 'dummy_db' to 'information_schema'
2025-05-12 21:18:12,463 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 21:18:12,463 - config - INFO - Executing query (DB: information_schema): SELECT TABLE_NAME FROM information_schema.TABLES WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s...
2025-05-12 21:18:12,463 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 21:18:12,463 - config - INFO - Executing query (DB: information_schema): 
        SELECT COUNT(T1.TABLE_NAME) AS vector_store_count
        FROM information_schema.COLUMNS A...
2025-05-12 21:18:12,640 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 21:18:12,640 - config - INFO - Executing query (DB: dummy_db): DROP TABLE IF EXISTS `VDB_tbl`;...
2025-05-12 21:18:12,640 - config - INFO - Switching database context from 'information_schema' to 'dummy_db'
2025-05-12 21:18:12,683 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-12 21:18:12,684 - config - INFO - TOOL END: delete_vector_store. Vector store 'VDB_tbl' deleted successfully from database 'dummy_db'.
2025-05-12 21:19:50,332 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 21:19:50,333 - config - INFO - TOOL START: list_databases called.
2025-05-12 21:19:50,333 - config - INFO - Executing query (DB: Chinook): SHOW DATABASES...
2025-05-12 21:19:50,335 - config - INFO - Query executed successfully, 9 rows returned.
2025-05-12 21:19:50,336 - config - INFO - TOOL END: list_databases completed. Databases found: 9.
2025-05-12 21:20:01,539 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 21:20:01,539 - config - INFO - TOOL START: list_vector_stores called for database: 'chinook'
2025-05-12 21:20:01,540 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 21:20:01,541 - config - INFO - Switching database context from 'dummy_db' to 'information_schema'
2025-05-12 21:20:01,542 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 21:20:01,543 - config - INFO - Executing query (DB: information_schema): 
        SELECT DISTINCT T1.TABLE_NAME
        FROM information_schema.COLUMNS AS T1
        INNER J...
2025-05-12 21:20:01,741 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-12 21:20:01,741 - config - INFO - No vector stores found in database 'chinook'.
2025-05-12 21:20:01,748 - config - INFO - TOOL END: list_vector_stores completed for database 'chinook'.
2025-05-12 21:20:24,717 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 21:20:24,718 - config - INFO - TOOL START: list_vector_stores called for database: 'dummy_db'
2025-05-12 21:20:24,718 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 21:20:24,720 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 21:20:24,720 - config - INFO - Executing query (DB: information_schema): 
        SELECT DISTINCT T1.TABLE_NAME
        FROM information_schema.COLUMNS AS T1
        INNER J...
2025-05-12 21:20:24,888 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-12 21:20:24,888 - config - INFO - No vector stores found in database 'dummy_db'.
2025-05-12 21:20:24,890 - config - INFO - TOOL END: list_vector_stores completed for database 'dummy_db'.
2025-05-12 21:20:34,571 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 21:20:34,572 - config - INFO - TOOL START: list_vector_stores called for database: 'kb_chunks'
2025-05-12 21:20:34,572 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 21:20:34,575 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 21:20:34,576 - config - INFO - Executing query (DB: information_schema): 
        SELECT DISTINCT T1.TABLE_NAME
        FROM information_schema.COLUMNS AS T1
        INNER J...
2025-05-12 21:20:34,772 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 21:20:34,772 - config - INFO - Found 1 vector store(s) in database 'kb_chunks': ['langchain_embedding']
2025-05-12 21:20:34,772 - config - INFO - TOOL END: list_vector_stores completed for database 'kb_chunks'.
2025-05-12 21:20:42,985 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 21:20:42,986 - config - INFO - TOOL START: list_vector_stores called for database: 'kb_rag'
2025-05-12 21:20:42,986 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 21:20:42,988 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 21:20:42,989 - config - INFO - Executing query (DB: information_schema): 
        SELECT DISTINCT T1.TABLE_NAME
        FROM information_schema.COLUMNS AS T1
        INNER J...
2025-05-12 21:20:43,175 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 21:20:43,175 - config - INFO - Found 1 vector store(s) in database 'kb_rag': ['langchain_embedding']
2025-05-12 21:20:43,175 - config - INFO - TOOL END: list_vector_stores completed for database 'kb_rag'.
2025-05-12 21:20:50,013 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 21:20:50,013 - config - INFO - TOOL START: list_vector_stores called for database: 'dummy_db'
2025-05-12 21:20:50,013 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 21:20:50,015 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 21:20:50,016 - config - INFO - Executing query (DB: information_schema): 
        SELECT DISTINCT T1.TABLE_NAME
        FROM information_schema.COLUMNS AS T1
        INNER J...
2025-05-12 21:20:50,192 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-12 21:20:50,192 - config - INFO - No vector stores found in database 'dummy_db'.
2025-05-12 21:20:50,192 - config - INFO - TOOL END: list_vector_stores completed for database 'dummy_db'.
2025-05-12 21:20:57,368 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 21:20:57,368 - config - INFO - TOOL START: list_vector_stores called for database: 'dummy_db'
2025-05-12 21:20:57,369 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 21:20:57,371 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 21:20:57,372 - config - INFO - Executing query (DB: information_schema): 
        SELECT DISTINCT T1.TABLE_NAME
        FROM information_schema.COLUMNS AS T1
        INNER J...
2025-05-12 21:20:57,616 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-12 21:20:57,617 - config - INFO - No vector stores found in database 'dummy_db'.
2025-05-12 21:20:57,617 - config - INFO - TOOL END: list_vector_stores completed for database 'dummy_db'.
2025-05-12 21:21:04,229 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 21:21:04,229 - config - INFO - TOOL START: list_vector_stores called for database: 'dummy_db'
2025-05-12 21:21:04,230 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 21:21:04,232 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 21:21:04,233 - config - INFO - Executing query (DB: information_schema): 
        SELECT DISTINCT T1.TABLE_NAME
        FROM information_schema.COLUMNS AS T1
        INNER J...
2025-05-12 21:21:04,406 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-12 21:21:04,406 - config - INFO - No vector stores found in database 'dummy_db'.
2025-05-12 21:21:04,406 - config - INFO - TOOL END: list_vector_stores completed for database 'dummy_db'.
2025-05-12 21:21:08,176 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 21:21:08,176 - config - INFO - TOOL START: list_vector_stores called for database: 'dummy_db'
2025-05-12 21:21:08,177 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 21:21:08,178 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 21:21:08,179 - config - INFO - Executing query (DB: information_schema): 
        SELECT DISTINCT T1.TABLE_NAME
        FROM information_schema.COLUMNS AS T1
        INNER J...
2025-05-12 21:21:08,355 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-12 21:21:08,355 - config - INFO - No vector stores found in database 'dummy_db'.
2025-05-12 21:21:08,355 - config - INFO - TOOL END: list_vector_stores completed for database 'dummy_db'.
2025-05-12 21:21:17,426 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 21:21:17,427 - config - INFO - TOOL START: list_vector_stores called for database: 'dummy_db'
2025-05-12 21:21:17,428 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 21:21:17,429 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 21:21:17,430 - config - INFO - Executing query (DB: information_schema): 
        SELECT DISTINCT T1.TABLE_NAME
        FROM information_schema.COLUMNS AS T1
        INNER J...
2025-05-12 21:21:17,653 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-12 21:21:17,653 - config - INFO - No vector stores found in database 'dummy_db'.
2025-05-12 21:21:17,653 - config - INFO - TOOL END: list_vector_stores completed for database 'dummy_db'.
2025-05-12 21:23:55,442 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 21:23:55,443 - config - INFO - TOOL START: create_vector_store called. DB: 'dummy_db', Store: 'vdb_tbl', Model: 'None', Embedding_Length: 1536, Distance_Requested: 'None'
2025-05-12 21:23:55,445 - config - INFO - Distance function not provided, defaulting to 'COSINE'.
2025-05-12 21:23:55,445 - config - INFO - Using SQL distance function: 'COSINE'.
2025-05-12 21:23:55,446 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-12 21:23:55,447 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-12 21:23:55,447 - config - INFO - Executing query (DB: information_schema): SELECT TABLE_NAME FROM information_schema.TABLES WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s...
2025-05-12 21:23:55,447 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-12 21:23:55,447 - config - INFO - Executing query (DB: dummy_db): 
        CREATE TABLE IF NOT EXISTS `vdb_tbl` (
            id VARCHAR(36) NOT NULL DEFAULT UUID_v7(...
2025-05-12 21:23:55,447 - config - INFO - Switching database context from 'information_schema' to 'dummy_db'
2025-05-12 21:23:55,494 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-12 21:23:55,494 - config - INFO - TOOL END: create_vector_store completed. Vector store 'vdb_tbl' created successfully in database 'dummy_db' with COSINE distance.
2025-05-12 21:24:31,410 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-12 21:24:31,410 - config - INFO - TOOL START: get_table_schema called. database_name=dummy_db, table_name=vdb_tbl
2025-05-12 21:24:31,411 - config - INFO - Executing query (DB: Chinook): DESCRIBE `dummy_db`.`vdb_tbl`...
2025-05-12 21:24:31,475 - config - INFO - Query executed successfully, 4 rows returned.
2025-05-12 21:24:31,476 - config - INFO - TOOL END: get_table_schema completed. Columns found: 4. Keys: ['id', 'document', 'embedding', 'metadata']
2025-05-13 10:01:30,282 - config - INFO - Selected Embedding Provider: openai
2025-05-13 10:01:30,283 - config - INFO - Read-only mode: False
2025-05-13 10:01:30,284 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 10:01:32,552 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 10:01:33,743 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 10:01:33,784 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 10:01:33,801 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 10:01:33,831 - config - INFO - Connection pool initialized successfully.
2025-05-13 10:01:33,859 - config - INFO - Registered MCP tools explicitly.
2025-05-13 10:01:33,860 - config - INFO - Starting MCP server via stdio...
2025-05-13 10:01:33,921 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 10:01:33,926 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 10:01:33,929 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-13 10:01:33,954 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-13 10:25:09,149 - config - INFO - Selected Embedding Provider: openai
2025-05-13 10:25:09,150 - config - INFO - Read-only mode: False
2025-05-13 10:25:09,150 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 10:25:11,902 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 10:25:13,484 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 10:25:13,528 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 10:25:13,561 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 10:25:13,604 - config - INFO - Connection pool initialized successfully.
2025-05-13 10:25:13,617 - config - INFO - Registered MCP tools explicitly.
2025-05-13 10:25:13,619 - config - INFO - Starting MCP server via stdio...
2025-05-13 10:25:13,647 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 10:44:39,888 - config - INFO - Selected Embedding Provider: openai
2025-05-13 10:44:39,888 - config - INFO - Read-only mode: False
2025-05-13 10:44:39,888 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 10:44:40,507 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 10:44:40,904 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 10:44:40,908 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 10:44:40,923 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 10:44:40,935 - config - INFO - Connection pool initialized successfully.
2025-05-13 10:44:40,938 - config - INFO - Registered MCP tools explicitly.
2025-05-13 10:44:40,942 - config - INFO - Starting MCP server via stdio...
2025-05-13 10:44:40,949 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 10:52:45,875 - config - INFO - Selected Embedding Provider: openai
2025-05-13 10:52:45,876 - config - INFO - Read-only mode: False
2025-05-13 10:52:45,876 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 10:52:46,540 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 10:52:47,005 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 10:52:47,015 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 10:52:47,021 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 10:52:47,033 - config - INFO - Connection pool initialized successfully.
2025-05-13 10:52:47,037 - config - INFO - Registered MCP tools explicitly.
2025-05-13 10:52:47,038 - config - INFO - Starting MCP server via stdio...
2025-05-13 10:52:47,044 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:15:18,172 - config - INFO - Selected Embedding Provider: openai
2025-05-13 11:15:18,172 - config - INFO - Selected Embedding Provider: openai
2025-05-13 11:15:18,173 - config - INFO - Selected Embedding Provider: openai
2025-05-13 11:15:18,173 - config - INFO - Read-only mode: False
2025-05-13 11:15:18,173 - config - INFO - Read-only mode: False
2025-05-13 11:15:18,174 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 11:15:18,174 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 11:15:18,174 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 11:15:18,185 - config - INFO - Selected Embedding Provider: openai
2025-05-13 11:15:18,185 - config - INFO - Read-only mode: False
2025-05-13 11:15:18,186 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 11:15:18,186 - config - INFO - Selected Embedding Provider: openai
2025-05-13 11:15:18,187 - config - INFO - Read-only mode: False
2025-05-13 11:15:18,189 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 11:15:19,176 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 11:15:19,176 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 11:15:19,176 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 11:15:19,180 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 11:15:19,182 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 11:15:20,148 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 11:15:20,148 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 11:15:20,148 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 11:15:20,164 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 11:15:20,164 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 11:15:20,164 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 11:15:20,164 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 11:15:20,164 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 11:15:20,164 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 11:15:20,180 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 11:15:20,183 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 11:15:20,183 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 11:15:20,183 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 11:15:20,183 - config - INFO - Connection pool initialized successfully.
2025-05-13 11:15:20,183 - config - INFO - Connection pool initialized successfully.
2025-05-13 11:15:20,183 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 11:15:20,196 - config - INFO - Connection pool initialized successfully.
2025-05-13 11:15:20,196 - config - INFO - Registered MCP tools explicitly.
2025-05-13 11:15:20,196 - config - INFO - Starting MCP server via stdio...
2025-05-13 11:15:20,196 - config - INFO - Registered MCP tools explicitly.
2025-05-13 11:15:20,196 - config - INFO - Starting MCP server via stdio...
2025-05-13 11:15:20,196 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 11:15:20,196 - config - INFO - Registered MCP tools explicitly.
2025-05-13 11:15:20,196 - config - INFO - Starting MCP server via stdio...
2025-05-13 11:15:20,196 - config - INFO - Connection pool initialized successfully.
2025-05-13 11:15:20,217 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:15:20,218 - config - INFO - Registered MCP tools explicitly.
2025-05-13 11:15:20,219 - config - INFO - Starting MCP server via stdio...
2025-05-13 11:15:20,219 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:15:20,224 - config - INFO - Connection pool initialized successfully.
2025-05-13 11:15:20,224 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:15:20,226 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:15:20,232 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:15:20,234 - config - INFO - Registered MCP tools explicitly.
2025-05-13 11:15:20,234 - config - INFO - Starting MCP server via stdio...
2025-05-13 11:15:20,234 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:18:41,813 - config - INFO - Selected Embedding Provider: openai
2025-05-13 11:18:41,813 - config - INFO - Read-only mode: False
2025-05-13 11:18:41,814 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 11:18:42,592 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 11:18:43,024 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 11:18:43,031 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 11:18:43,037 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 11:18:43,057 - config - INFO - Connection pool initialized successfully.
2025-05-13 11:18:43,062 - config - INFO - Registered MCP tools explicitly.
2025-05-13 11:18:43,063 - config - INFO - Starting MCP server via stdio...
2025-05-13 11:18:43,071 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:23:09,829 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-13 11:23:20,045 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-13 11:23:26,101 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-05-13 11:23:26,325 - config - ERROR - Failed to insert docs into test_db.test_vector_store: (1146, "Table 'test_db.test_vector_store' doesn't exist")
Traceback (most recent call last):
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 632, in insert_docs_vector_store
  File "asyncmy\\cursors.pyx", line 225, in executemany
  File "asyncmy\\cursors.pyx", line 179, in execute
  File "asyncmy\\cursors.pyx", line 364, in _query
  File "asyncmy\\connection.pyx", line 496, in query
  File "asyncmy\\connection.pyx", line 684, in _read_query_result
  File "asyncmy\\connection.pyx", line 1071, in read
  File "asyncmy\\connection.pyx", line 646, in read_packet
  File "asyncmy\\protocol.pyx", line 190, in asyncmy.protocol.MysqlPacket.raise_for_error
  File "asyncmy\\protocol.pyx", line 194, in asyncmy.protocol.MysqlPacket.raise_for_error
  File "asyncmy\\errors.pyx", line 128, in asyncmy.errors.raise_mysql_exception
  File "asyncmy\\errors.pyx", line 137, in asyncmy.errors.raise_mysql_exception
asyncmy.errors.ProgrammingError: (1146, "Table 'test_db.test_vector_store' doesn't exist")
2025-05-13 11:24:50,038 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-13 11:24:50,040 - config - INFO - TOOL START: create_vector_store called. DB: 'test_db', Store: 'test_vector_store', Model: 'None', Embedding_Length: 1536, Distance_Requested: 'None'
2025-05-13 11:24:50,040 - config - INFO - Distance function not provided, defaulting to 'COSINE'.
2025-05-13 11:24:50,041 - config - INFO - Using SQL distance function: 'COSINE'.
2025-05-13 11:24:50,041 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-13 11:24:50,071 - config - INFO - Switching database context from 'chinook' to 'information_schema'
2025-05-13 11:24:50,074 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-13 11:24:50,075 - config - INFO - Executing query (DB: information_schema): SELECT TABLE_NAME FROM information_schema.TABLES WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s...
2025-05-13 11:24:50,076 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-13 11:24:50,077 - config - INFO - Executing query (DB: test_db): 
        CREATE TABLE IF NOT EXISTS `test_vector_store` (
            id VARCHAR(36) NOT NULL DEFAUL...
2025-05-13 11:24:50,078 - config - INFO - Switching database context from 'information_schema' to 'test_db'
2025-05-13 11:24:50,117 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-13 11:24:50,118 - config - INFO - TOOL END: create_vector_store completed. Vector store 'test_vector_store' created successfully in database 'test_db' with COSINE distance.
2025-05-13 11:29:38,799 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-13 11:29:38,802 - config - CRITICAL - Server execution failed with an unexpected error: unhandled errors in a TaskGroup (2 sub-exceptions)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 695, in run_async_server
  |     finally:
  |         ^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (2 sub-exceptions)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 79, in stdout_writer
    |     await stdout.flush()
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_core\_fileio.py", line 140, in flush
    |     return await to_thread.run_sync(self._fp.flush)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    |     return await get_async_backend().run_sync_in_worker_thread(
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2470, in run_sync_in_worker_thread
    |     return await future
    |            ^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    |     result = context.run(func, *args)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
    | OSError: [Errno 22] Invalid argument
    +---------------- 2 ----------------
    | Exception Group Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 86, in stdio_server
    |     yield read_stream, write_stream
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 812, in run_stdio_async
    |     await self._mcp_server.run(
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 483, in run
    |     async with AsyncExitStack() as stack:
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 745, in __aexit__
    |     raise exc_details[1]
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 728, in __aexit__
    |     cb_suppress = await cb(*exc_details)
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 209, in __aexit__
    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
    |     raise BaseExceptionGroup(
    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
    +-+---------------- 1 ----------------
      | Exception Group Traceback (most recent call last):
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 489, in run
      |     async with anyio.create_task_group() as tg:
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
      |     raise BaseExceptionGroup(
      | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
      +-+---------------- 1 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\streams\memory.py", line 255, in send
        |     raise BrokenResourceError from None
        | anyio.BrokenResourceError
        +------------------------------------
2025-05-13 11:29:38,943 - config - INFO - Closing database connection pool...
2025-05-13 11:29:38,944 - config - INFO - Database connection pool closed.
2025-05-13 11:29:38,948 - config - CRITICAL - Server failed to start or crashed: unhandled errors in a TaskGroup (2 sub-exceptions)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 724, in <module>
  |     logger.critical(f"Server failed to start or crashed: {e}", exc_info=True)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_core\_eventloop.py", line 74, in run
  |     return async_backend.run(func, args, {}, backend_options)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2310, in run
  |     return runner.run(wrapper())
  |            ^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\runners.py", line 118, in run
  |     return self._loop.run_until_complete(task)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\base_events.py", line 653, in run_until_complete
  |     return future.result()
  |            ^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2298, in wrapper
  |     return await func(*args)
  |            ^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\server.py", line 695, in run_async_server
  |     finally:
  |         ^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (2 sub-exceptions)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 79, in stdout_writer
    |     await stdout.flush()
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_core\_fileio.py", line 140, in flush
    |     return await to_thread.run_sync(self._fp.flush)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    |     return await get_async_backend().run_sync_in_worker_thread(
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2470, in run_sync_in_worker_thread
    |     return await future
    |            ^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    |     result = context.run(func, *args)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
    | OSError: [Errno 22] Invalid argument
    +---------------- 2 ----------------
    | Exception Group Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\stdio.py", line 86, in stdio_server
    |     yield read_stream, write_stream
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\fastmcp\server\server.py", line 812, in run_stdio_async
    |     await self._mcp_server.run(
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 483, in run
    |     async with AsyncExitStack() as stack:
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 745, in __aexit__
    |     raise exc_details[1]
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 728, in __aexit__
    |     cb_suppress = await cb(*exc_details)
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 209, in __aexit__
    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
    |     raise BaseExceptionGroup(
    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
    +-+---------------- 1 ----------------
      | Exception Group Traceback (most recent call last):
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 489, in run
      |     async with anyio.create_task_group() as tg:
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
      |     raise BaseExceptionGroup(
      | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
      +-+---------------- 1 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server\.venv\Lib\site-packages\anyio\streams\memory.py", line 255, in send
        |     raise BrokenResourceError from None
        | anyio.BrokenResourceError
        +------------------------------------
2025-05-13 11:29:38,985 - config - INFO - Server exiting with code 1.
2025-05-13 11:29:46,543 - config - INFO - Selected Embedding Provider: openai
2025-05-13 11:29:46,543 - config - INFO - Read-only mode: False
2025-05-13 11:29:46,543 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 11:29:47,222 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 11:29:47,613 - config - INFO - Selected Embedding Provider: openai
2025-05-13 11:29:47,613 - config - INFO - Read-only mode: False
2025-05-13 11:29:47,613 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 11:29:47,691 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 11:29:47,691 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 11:29:47,707 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 11:29:47,722 - config - INFO - Connection pool initialized successfully.
2025-05-13 11:29:47,723 - config - INFO - Registered MCP tools explicitly.
2025-05-13 11:29:47,723 - config - INFO - Starting MCP server via stdio...
2025-05-13 11:29:47,723 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:29:48,316 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 11:29:48,883 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 11:29:48,894 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 11:29:48,903 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 11:29:48,916 - config - INFO - Connection pool initialized successfully.
2025-05-13 11:29:48,925 - config - INFO - Registered MCP tools explicitly.
2025-05-13 11:29:48,926 - config - INFO - Starting MCP server via stdio...
2025-05-13 11:29:48,933 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:29:49,677 - config - INFO - Selected Embedding Provider: openai
2025-05-13 11:29:49,677 - config - INFO - Read-only mode: False
2025-05-13 11:29:49,677 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 11:29:50,369 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 11:29:50,853 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 11:29:50,868 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 11:29:50,878 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 11:29:50,896 - config - INFO - Connection pool initialized successfully.
2025-05-13 11:29:50,901 - config - INFO - Registered MCP tools explicitly.
2025-05-13 11:29:50,901 - config - INFO - Starting MCP server via stdio...
2025-05-13 11:29:50,909 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:30:21,114 - config - INFO - Selected Embedding Provider: openai
2025-05-13 11:30:21,114 - config - INFO - Read-only mode: False
2025-05-13 11:30:21,116 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 11:30:22,167 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 11:30:22,716 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 11:30:22,728 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 11:30:22,736 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 11:30:22,751 - config - INFO - Connection pool initialized successfully.
2025-05-13 11:30:22,757 - config - INFO - Registered MCP tools explicitly.
2025-05-13 11:30:22,758 - config - INFO - Starting MCP server via stdio...
2025-05-13 11:30:22,765 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:36:19,368 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-13 11:36:27,393 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-13 11:36:28,934 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-05-13 11:36:28,937 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vector_store` (document, embedding, metadata) VALUES (%s, VEC_FromText(%...
2025-05-13 11:36:28,938 - config - INFO - Switching database context from 'chinook' to 'test_db'
2025-05-13 11:36:28,979 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-13 11:36:28,980 - config - INFO - Inserted 1 documents into test_db.test_vector_store (errors: 0)
2025-05-13 11:39:10,575 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-13 11:39:24,137 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-13 11:39:25,183 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-05-13 11:39:25,389 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vector_store` (document, embedding, metadata) VALUES (%s, VEC_FromText(%...
2025-05-13 11:39:25,430 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-13 11:39:25,434 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vector_store` (document, embedding, metadata) VALUES (%s, VEC_FromText(%...
2025-05-13 11:39:25,444 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-13 11:39:25,444 - config - INFO - Inserted 2 documents into test_db.test_vector_store (errors: 0)
2025-05-13 11:41:42,102 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-13 11:41:42,103 - config - INFO - TOOL START: execute_sql called. database_name=test_db, sql_query=SELECT COUNT(*) as count FROM test_vector_store, parameters=None
2025-05-13 11:41:42,104 - config - INFO - Executing query (DB: test_db): SELECT COUNT(*) as count FROM test_vector_store...
2025-05-13 11:41:42,106 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-13 11:41:42,107 - config - INFO - TOOL END: execute_sql completed. Rows returned: 1.
2025-05-13 11:42:35,861 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-13 11:42:35,862 - config - INFO - TOOL START: execute_sql called. database_name=test_db, sql_query=SELECT document FROM test_vector_store, parameters=None
2025-05-13 11:42:35,862 - config - INFO - Executing query (DB: test_db): SELECT document FROM test_vector_store...
2025-05-13 11:42:35,865 - config - INFO - Query executed successfully, 3 rows returned.
2025-05-13 11:42:35,866 - config - INFO - TOOL END: execute_sql completed. Rows returned: 3.
2025-05-13 11:43:22,414 - config - INFO - Selected Embedding Provider: openai
2025-05-13 11:43:22,414 - config - INFO - Selected Embedding Provider: openai
2025-05-13 11:43:22,414 - config - INFO - Selected Embedding Provider: openai
2025-05-13 11:43:22,414 - config - INFO - Read-only mode: False
2025-05-13 11:43:22,414 - config - INFO - Read-only mode: False
2025-05-13 11:43:22,414 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 11:43:22,414 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 11:43:23,529 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 11:43:23,546 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 11:43:23,560 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 11:43:24,639 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 11:43:24,648 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 11:43:24,664 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 11:43:24,668 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 11:43:24,674 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 11:43:24,686 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 11:43:24,691 - config - INFO - Connection pool initialized successfully.
2025-05-13 11:43:24,691 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 11:43:24,699 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 11:43:24,699 - config - INFO - Registered MCP tools explicitly.
2025-05-13 11:43:24,699 - config - INFO - Starting MCP server via stdio...
2025-05-13 11:43:24,707 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 11:43:24,723 - config - INFO - Connection pool initialized successfully.
2025-05-13 11:43:24,724 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:43:24,729 - config - INFO - Connection pool initialized successfully.
2025-05-13 11:43:24,735 - config - INFO - Registered MCP tools explicitly.
2025-05-13 11:43:24,735 - config - INFO - Starting MCP server via stdio...
2025-05-13 11:43:24,739 - config - INFO - Registered MCP tools explicitly.
2025-05-13 11:43:24,740 - config - INFO - Starting MCP server via stdio...
2025-05-13 11:43:24,754 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:43:24,757 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:43:24,759 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:43:26,302 - config - INFO - Selected Embedding Provider: openai
2025-05-13 11:43:26,302 - config - INFO - Read-only mode: False
2025-05-13 11:43:26,302 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 11:43:27,068 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 11:43:27,744 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 11:43:27,756 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 11:43:27,768 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 11:43:27,786 - config - INFO - Connection pool initialized successfully.
2025-05-13 11:43:27,791 - config - INFO - Registered MCP tools explicitly.
2025-05-13 11:43:27,791 - config - INFO - Starting MCP server via stdio...
2025-05-13 11:43:27,806 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:43:28,347 - config - INFO - Selected Embedding Provider: openai
2025-05-13 11:43:28,347 - config - INFO - Read-only mode: False
2025-05-13 11:43:28,348 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 11:43:29,042 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 11:43:29,547 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 11:43:29,557 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 11:43:29,564 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 11:43:29,581 - config - INFO - Connection pool initialized successfully.
2025-05-13 11:43:29,588 - config - INFO - Registered MCP tools explicitly.
2025-05-13 11:43:29,588 - config - INFO - Starting MCP server via stdio...
2025-05-13 11:43:29,601 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 11:44:08,034 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-13 11:44:08,035 - config - INFO - TOOL START: list_vector_stores called for database: 'test_db'
2025-05-13 11:44:08,036 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-13 11:44:08,037 - config - INFO - Switching database context from 'chinook' to 'information_schema'
2025-05-13 11:44:08,040 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-13 11:44:08,041 - config - INFO - Executing query (DB: information_schema): 
        SELECT DISTINCT T1.TABLE_NAME
        FROM information_schema.COLUMNS AS T1
        INNER J...
2025-05-13 11:44:08,230 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-13 11:44:08,230 - config - INFO - Found 1 vector store(s) in database 'test_db': ['test_vector_store']
2025-05-13 11:44:08,231 - config - INFO - TOOL END: list_vector_stores completed for database 'test_db'.
2025-05-13 11:44:22,552 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-13 11:44:22,553 - config - INFO - TOOL START: execute_sql called. database_name=test_db, sql_query=SELECT id, document, metadata FROM test_vector_store, parameters=None
2025-05-13 11:44:22,553 - config - INFO - Executing query (DB: test_db): SELECT id, document, metadata FROM test_vector_store...
2025-05-13 11:44:22,555 - config - INFO - Switching database context from 'information_schema' to 'test_db'
2025-05-13 11:44:22,556 - config - INFO - Query executed successfully, 3 rows returned.
2025-05-13 11:44:22,557 - config - INFO - TOOL END: execute_sql completed. Rows returned: 3.
2025-05-13 12:19:06,163 - config - INFO - Selected Embedding Provider: openai
2025-05-13 12:19:06,163 - config - INFO - Selected Embedding Provider: openai
2025-05-13 12:19:06,163 - config - INFO - Read-only mode: False
2025-05-13 12:19:06,163 - config - INFO - Read-only mode: False
2025-05-13 12:19:06,163 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 12:19:06,163 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 12:19:06,180 - config - INFO - Selected Embedding Provider: openai
2025-05-13 12:19:06,180 - config - INFO - Read-only mode: False
2025-05-13 12:19:06,180 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 12:19:07,140 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 12:19:07,140 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 12:19:07,140 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 12:19:07,422 - config - INFO - Selected Embedding Provider: openai
2025-05-13 12:19:07,422 - config - INFO - Read-only mode: False
2025-05-13 12:19:07,422 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 12:19:08,120 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 12:19:08,165 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 12:19:08,170 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 12:19:08,177 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 12:19:08,177 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 12:19:08,177 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 12:19:08,177 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 12:19:08,177 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 12:19:08,192 - config - INFO - Connection pool initialized successfully.
2025-05-13 12:19:08,192 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 12:19:08,192 - config - INFO - Connection pool initialized successfully.
2025-05-13 12:19:08,207 - config - INFO - Registered MCP tools explicitly.
2025-05-13 12:19:08,207 - config - INFO - Starting MCP server via stdio...
2025-05-13 12:19:08,207 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 12:19:08,207 - config - INFO - Registered MCP tools explicitly.
2025-05-13 12:19:08,207 - config - INFO - Starting MCP server via stdio...
2025-05-13 12:19:08,207 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 12:19:08,226 - config - INFO - Connection pool initialized successfully.
2025-05-13 12:19:08,228 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 12:19:08,228 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 12:19:08,228 - config - INFO - Registered MCP tools explicitly.
2025-05-13 12:19:08,228 - config - INFO - Starting MCP server via stdio...
2025-05-13 12:19:08,248 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 12:19:08,601 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 12:19:08,616 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 12:19:08,616 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 12:19:08,632 - config - INFO - Connection pool initialized successfully.
2025-05-13 12:19:08,650 - config - INFO - Registered MCP tools explicitly.
2025-05-13 12:19:08,650 - config - INFO - Starting MCP server via stdio...
2025-05-13 12:19:08,663 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 12:19:09,731 - config - INFO - Selected Embedding Provider: openai
2025-05-13 12:19:09,731 - config - INFO - Read-only mode: False
2025-05-13 12:19:09,732 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 12:19:10,390 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 12:19:10,784 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 12:19:10,799 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 12:19:10,799 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 12:19:10,818 - config - INFO - Connection pool initialized successfully.
2025-05-13 12:19:10,818 - config - INFO - Registered MCP tools explicitly.
2025-05-13 12:19:10,818 - config - INFO - Starting MCP server via stdio...
2025-05-13 12:19:10,833 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 12:20:10,649 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-13 12:20:12,114 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-05-13 12:20:12,593 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vector_store` (document, embedding, metadata) VALUES (%s, VEC_FromText(%...
2025-05-13 12:20:12,595 - config - INFO - Switching database context from 'chinook' to 'test_db'
2025-05-13 12:20:12,625 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-13 12:20:12,641 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vector_store` (document, embedding, metadata) VALUES (%s, VEC_FromText(%...
2025-05-13 12:20:12,657 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-13 12:20:12,660 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vector_store` (document, embedding, metadata) VALUES (%s, VEC_FromText(%...
2025-05-13 12:20:12,664 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-13 12:20:12,676 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vector_store` (document, embedding, metadata) VALUES (%s, VEC_FromText(%...
2025-05-13 12:20:12,686 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-13 12:20:12,688 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vector_store` (document, embedding, metadata) VALUES (%s, VEC_FromText(%...
2025-05-13 12:20:12,698 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-13 12:20:12,701 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vector_store` (document, embedding, metadata) VALUES (%s, VEC_FromText(%...
2025-05-13 12:20:12,707 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-13 12:20:12,708 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vector_store` (document, embedding, metadata) VALUES (%s, VEC_FromText(%...
2025-05-13 12:20:12,708 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-13 12:20:12,708 - config - INFO - Inserted 7 documents into test_db.test_vector_store (errors: 0)
2025-05-13 12:22:07,945 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-13 12:23:05,131 - config - INFO - Selected Embedding Provider: openai
2025-05-13 12:23:05,131 - config - INFO - Read-only mode: False
2025-05-13 12:23:05,131 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 12:23:05,776 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 12:23:06,184 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 12:23:06,202 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 12:23:06,202 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 12:23:06,216 - config - INFO - Connection pool initialized successfully.
2025-05-13 12:23:06,232 - config - INFO - Registered MCP tools explicitly.
2025-05-13 12:23:06,232 - config - INFO - Starting MCP server via stdio...
2025-05-13 12:23:06,232 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 12:23:07,785 - config - INFO - Selected Embedding Provider: openai
2025-05-13 12:23:07,785 - config - INFO - Read-only mode: False
2025-05-13 12:23:07,786 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 12:23:08,468 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 12:23:08,908 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 12:23:08,924 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 12:23:08,924 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 12:23:08,939 - config - INFO - Connection pool initialized successfully.
2025-05-13 12:23:08,939 - config - INFO - Registered MCP tools explicitly.
2025-05-13 12:23:08,939 - config - INFO - Starting MCP server via stdio...
2025-05-13 12:23:08,958 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 12:23:12,123 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 12:23:14,467 - config - INFO - Selected Embedding Provider: openai
2025-05-13 12:23:14,467 - config - INFO - Read-only mode: False
2025-05-13 12:23:14,467 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 12:23:15,132 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 12:23:15,549 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 12:23:15,558 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 12:23:15,564 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 12:23:15,579 - config - INFO - Connection pool initialized successfully.
2025-05-13 12:23:15,582 - config - INFO - Registered MCP tools explicitly.
2025-05-13 12:23:15,582 - config - INFO - Starting MCP server via stdio...
2025-05-13 12:23:15,582 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 12:23:31,011 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-13 12:23:32,388 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-05-13 12:23:32,392 - config - INFO - Executing query (DB: test_db): 
            SELECT 
                document,
                metadata,
                VEC_DISTANC...
2025-05-13 12:23:32,394 - config - INFO - Switching database context from 'chinook' to 'test_db'
2025-05-13 12:23:32,400 - config - INFO - Query executed successfully, 7 rows returned.
2025-05-13 12:23:32,400 - config - INFO - Semantic search in test_db.test_vector_store returned 7 results.
2025-05-13 14:17:49,488 - config - INFO - Selected Embedding Provider: openai
2025-05-13 14:17:49,488 - config - INFO - Read-only mode: False
2025-05-13 14:17:49,489 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 14:17:50,510 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 14:17:51,003 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 14:17:51,068 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 14:17:51,082 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 14:17:51,106 - config - INFO - Connection pool initialized successfully.
2025-05-13 14:17:51,128 - config - INFO - Registered MCP tools explicitly.
2025-05-13 14:17:51,129 - config - INFO - Starting MCP server via stdio...
2025-05-13 14:17:51,147 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 15:24:29,302 - config - INFO - Selected Embedding Provider: openai
2025-05-13 15:24:29,302 - config - INFO - Read-only mode: False
2025-05-13 15:24:29,303 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 15:24:30,237 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 15:24:30,664 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 15:24:30,677 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 15:24:30,684 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 15:24:30,707 - config - INFO - Connection pool initialized successfully.
2025-05-13 15:24:30,712 - config - INFO - Registered MCP tools explicitly.
2025-05-13 15:24:30,714 - config - INFO - Starting MCP server via stdio...
2025-05-13 15:24:30,721 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-13 20:11:03,571 - config - INFO - Selected Embedding Provider: openai
2025-05-13 20:11:03,572 - config - INFO - Read-only mode: False
2025-05-13 20:11:03,572 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-13 20:11:04,513 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-13 20:11:05,148 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-13 20:11:05,163 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-13 20:11:05,171 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-13 20:11:05,191 - config - INFO - Connection pool initialized successfully.
2025-05-13 20:11:05,202 - config - INFO - Registered MCP tools explicitly.
2025-05-13 20:11:05,203 - config - INFO - Starting MCP server via stdio...
2025-05-13 20:11:05,212 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 07:29:56,906 - config - INFO - Selected Embedding Provider: openai
2025-05-14 07:29:56,950 - config - INFO - Read-only mode: False
2025-05-14 07:29:56,951 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 07:29:59,512 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-14 07:30:01,067 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-14 07:30:01,113 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-14 07:30:01,170 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-14 07:30:01,316 - config - INFO - Connection pool initialized successfully.
2025-05-14 07:30:01,334 - config - INFO - Registered MCP tools explicitly.
2025-05-14 07:30:01,335 - config - INFO - Starting MCP server via stdio...
2025-05-14 07:30:01,395 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 07:30:01,395 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 07:30:01,395 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-14 07:30:01,426 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-14 11:42:20,395 - config - INFO - Selected Embedding Provider: openai
2025-05-14 11:42:20,395 - config - INFO - Read-only mode: False
2025-05-14 11:42:20,396 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 11:42:21,284 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-14 11:42:22,104 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-14 11:42:22,120 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-14 11:42:22,136 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-14 11:42:22,167 - config - INFO - Connection pool initialized successfully.
2025-05-14 11:42:22,183 - config - INFO - Registered MCP tools explicitly.
2025-05-14 11:42:22,183 - config - INFO - Starting MCP server via stdio...
2025-05-14 11:42:22,200 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 11:42:35,716 - config - INFO - Selected Embedding Provider: openai
2025-05-14 11:42:35,717 - config - INFO - Read-only mode: False
2025-05-14 11:42:35,719 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 11:42:38,177 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-14 11:42:39,102 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-14 11:42:39,119 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-14 11:42:39,130 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-14 11:42:39,150 - config - INFO - Connection pool initialized successfully.
2025-05-14 11:42:39,158 - config - INFO - Registered MCP tools explicitly.
2025-05-14 11:42:39,158 - config - INFO - Starting MCP server via stdio...
2025-05-14 11:42:39,167 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 19:19:32,758 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 19:19:32,758 - config - INFO - Read-only mode: False
2025-05-14 19:19:32,758 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 19:19:38,173 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available.
2025-05-14 19:19:38,175 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 19:19:38,175 - config - ERROR - Gemini provider selected, but 'google-genai' package is not installed.
2025-05-14 19:20:59,121 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 19:20:59,121 - config - INFO - Read-only mode: False
2025-05-14 19:20:59,121 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 19:21:00,623 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available.
2025-05-14 19:21:00,631 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 19:21:00,631 - config - ERROR - Gemini provider selected, but 'google-genai' package is not installed.
2025-05-14 19:22:47,482 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 19:22:47,482 - config - INFO - Read-only mode: False
2025-05-14 19:22:47,482 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 19:22:49,047 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available.
2025-05-14 19:22:49,047 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 19:22:49,048 - config - ERROR - Gemini provider selected, but 'google-genai' package is not installed.
2025-05-14 19:25:13,687 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 19:25:13,687 - config - INFO - Read-only mode: False
2025-05-14 19:25:13,688 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 19:25:15,211 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available.
2025-05-14 19:25:15,211 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 19:25:15,212 - config - ERROR - Gemini provider selected, but 'google-genai' package is not installed.
2025-05-14 19:27:32,050 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 19:27:32,050 - config - INFO - Read-only mode: False
2025-05-14 19:27:32,050 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 19:27:33,670 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available.
2025-05-14 19:27:33,670 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 19:27:33,670 - config - ERROR - Gemini provider selected, but 'google-genai' package is not installed.
2025-05-14 19:31:00,700 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 19:31:00,701 - config - INFO - Read-only mode: False
2025-05-14 19:31:00,701 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 19:31:02,623 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available.
2025-05-14 19:31:02,623 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 19:31:02,623 - config - ERROR - Gemini provider selected, but 'google-genai' package is not installed.
2025-05-14 19:35:48,845 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 19:35:48,845 - config - INFO - Read-only mode: False
2025-05-14 19:35:48,845 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 19:35:50,458 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 19:35:50,459 - config - INFO - Current sys.path: ['C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 19:35:50,459 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 19:35:50,459 - config - ERROR - Gemini provider selected, but 'google-genai' package is not installed.
2025-05-14 19:37:12,345 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 19:37:12,345 - config - INFO - Read-only mode: False
2025-05-14 19:37:12,345 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 19:37:13,073 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 19:37:13,073 - config - INFO - Current sys.path: ['C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 19:37:13,073 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 19:37:13,073 - config - ERROR - Gemini provider selected, but 'google-genai' package is not installed.
2025-05-14 19:38:14,101 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 19:38:14,101 - config - INFO - Read-only mode: False
2025-05-14 19:38:14,101 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 19:38:15,810 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 19:38:15,810 - config - INFO - Current sys.path: ['C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 19:38:15,810 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 19:38:15,810 - config - INFO - Successfully imported google.genai directly
2025-05-14 19:38:15,810 - config - ERROR - Failed to initialize Gemini client: module 'google.genai' has no attribute 'AsyncClient'
Traceback (most recent call last):
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\embeddings.py", line 110, in __init__
    self.gemini_client = genai.AsyncClient(api_key=GEMINI_API_KEY)
                         ^^^^^^^^^^^^^^^^^
AttributeError: module 'google.genai' has no attribute 'AsyncClient'
2025-05-14 19:41:51,871 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 19:41:51,871 - config - INFO - Read-only mode: False
2025-05-14 19:41:51,871 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 19:41:53,546 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 19:41:53,546 - config - INFO - Current sys.path: ['C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 19:41:53,548 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 19:41:53,548 - config - INFO - Successfully imported google.genai directly
2025-05-14 19:41:53,549 - config - ERROR - Failed to initialize Gemini client: module 'google.genai' has no attribute 'configure'
Traceback (most recent call last):
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\embeddings.py", line 111, in __init__
    genai.configure(api_key=GEMINI_API_KEY)
    ^^^^^^^^^^^^^^^
AttributeError: module 'google.genai' has no attribute 'configure'
2025-05-14 20:07:01,020 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 20:07:01,036 - config - INFO - Read-only mode: False
2025-05-14 20:07:01,036 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 20:07:03,440 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 20:07:03,441 - config - INFO - Current sys.path: ['C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 20:07:03,441 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 20:07:03,441 - config - INFO - Successfully imported google.genai directly
2025-05-14 20:07:03,441 - config - ERROR - Failed to initialize Gemini client: module 'google.genai' has no attribute 'configure'
Traceback (most recent call last):
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\embeddings.py", line 111, in __init__
    genai.configure(api_key=GEMINI_API_KEY)
    ^^^^^^^^^^^^^^^
AttributeError: module 'google.genai' has no attribute 'configure'
2025-05-14 20:12:24,150 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 20:12:24,151 - config - INFO - Read-only mode: False
2025-05-14 20:12:24,151 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 20:12:25,867 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 20:12:25,867 - config - INFO - Current sys.path: ['C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 20:12:25,868 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 20:12:25,869 - config - INFO - Successfully imported google.genai directly
2025-05-14 20:12:26,299 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-14 20:12:26,310 - config - INFO - Initializing MariaDB_Server...
2025-05-14 20:12:26,317 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-14 20:12:26,330 - config - INFO - Connection pool initialized successfully.
2025-05-14 20:12:26,336 - config - INFO - Registered MCP tools explicitly.
2025-05-14 20:12:26,337 - config - INFO - Starting MCP server via stdio...
2025-05-14 20:12:26,350 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 20:12:26,353 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 20:12:26,354 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-14 20:12:26,368 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-14 20:13:13,833 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 20:13:13,834 - config - INFO - Read-only mode: False
2025-05-14 20:13:13,834 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 20:13:15,369 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 20:13:15,370 - config - INFO - Current sys.path: ['C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 20:13:15,370 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 20:13:15,370 - config - INFO - Successfully imported google.genai directly
2025-05-14 20:13:15,758 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-14 20:13:15,768 - config - INFO - Initializing MariaDB_Server...
2025-05-14 20:13:15,778 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-14 20:13:15,797 - config - INFO - Connection pool initialized successfully.
2025-05-14 20:13:15,803 - config - INFO - Registered MCP tools explicitly.
2025-05-14 20:13:15,803 - config - INFO - Starting MCP server via stdio...
2025-05-14 20:13:15,816 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 20:15:57,907 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 20:15:57,907 - config - INFO - TOOL START: list_databases called.
2025-05-14 20:15:57,907 - config - INFO - Executing query (DB: Chinook): SHOW DATABASES...
2025-05-14 20:15:57,918 - config - INFO - Query executed successfully, 9 rows returned.
2025-05-14 20:15:57,919 - config - INFO - TOOL END: list_databases completed. Databases found: 9.
2025-05-14 20:16:01,741 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 20:16:01,742 - config - INFO - TOOL START: create_database called for database: 'test'
2025-05-14 20:16:01,743 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-14 20:16:01,744 - config - INFO - Switching database context from 'chinook' to 'information_schema'
2025-05-14 20:16:01,785 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-14 20:16:01,785 - config - INFO - Executing query (DB: Chinook): CREATE DATABASE IF NOT EXISTS `test`;...
2025-05-14 20:16:01,785 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-14 20:16:01,785 - config - INFO - TOOL END: create_database. Database 'test' created successfully.
2025-05-14 20:16:05,862 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 20:16:10,399 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 20:16:14,503 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 20:16:18,747 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 20:16:22,941 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 20:16:27,938 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 20:16:27,987 - config - INFO - TOOL START: list_databases called.
2025-05-14 20:16:27,987 - config - INFO - Executing query (DB: Chinook): SHOW DATABASES...
2025-05-14 20:18:50,661 - config - INFO - Query executed successfully, 10 rows returned.
2025-05-14 20:18:50,661 - config - INFO - TOOL END: list_databases completed. Databases found: 10.
2025-05-14 20:18:50,663 - config - CRITICAL - Server execution failed with an unexpected error: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Exception Group Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 86, in stdio_server
    |     yield read_stream, write_stream
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 812, in run_stdio_async
    |     await self._mcp_server.run(
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 483, in run
    |     async with AsyncExitStack() as stack:
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 745, in __aexit__
    |     raise exc_details[1]
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 728, in __aexit__
    |     cb_suppress = await cb(*exc_details)
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 209, in __aexit__
    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
    |     raise BaseExceptionGroup(
    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
    +-+---------------- 1 ----------------
      | Exception Group Traceback (most recent call last):
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 489, in run
      |     async with anyio.create_task_group() as tg:
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
      |     raise BaseExceptionGroup(
      | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
      +-+---------------- 1 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 242, in send
        |     self.send_nowait(item)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 211, in send_nowait
        |     raise ClosedResourceError
        | anyio.ClosedResourceError
        +------------------------------------
2025-05-14 20:18:50,745 - config - INFO - Closing database connection pool...
2025-05-14 20:18:50,746 - config - INFO - Database connection pool closed.
2025-05-14 20:18:50,748 - config - CRITICAL - Server failed to start or crashed: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 761, in <module>
  |     anyio.run(
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_eventloop.py", line 74, in run
  |     return async_backend.run(func, args, {}, backend_options)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2310, in run
  |     return runner.run(wrapper())
  |            ^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\runners.py", line 118, in run
  |     return self._loop.run_until_complete(task)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\base_events.py", line 653, in run_until_complete
  |     return future.result()
  |            ^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2298, in wrapper
  |     return await func(*args)
  |            ^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Exception Group Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 86, in stdio_server
    |     yield read_stream, write_stream
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 812, in run_stdio_async
    |     await self._mcp_server.run(
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 483, in run
    |     async with AsyncExitStack() as stack:
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 745, in __aexit__
    |     raise exc_details[1]
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 728, in __aexit__
    |     cb_suppress = await cb(*exc_details)
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 209, in __aexit__
    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
    |     raise BaseExceptionGroup(
    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
    +-+---------------- 1 ----------------
      | Exception Group Traceback (most recent call last):
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 489, in run
      |     async with anyio.create_task_group() as tg:
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
      |     raise BaseExceptionGroup(
      | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
      +-+---------------- 1 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 242, in send
        |     self.send_nowait(item)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 211, in send_nowait
        |     raise ClosedResourceError
        | anyio.ClosedResourceError
        +------------------------------------
2025-05-14 20:18:50,789 - config - INFO - Server exiting with code 1.
2025-05-14 20:39:14,311 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 20:39:14,312 - config - INFO - Read-only mode: False
2025-05-14 20:39:14,312 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 20:39:16,228 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 20:39:16,228 - config - INFO - Current sys.path: ['C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 20:39:16,229 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 20:39:16,229 - config - INFO - Successfully imported google.genai directly
2025-05-14 20:39:17,211 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-14 20:39:17,234 - config - INFO - Initializing MariaDB_Server...
2025-05-14 20:39:17,247 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-14 20:39:17,279 - config - INFO - Connection pool initialized successfully.
2025-05-14 20:39:17,292 - config - INFO - Registered MCP tools explicitly.
2025-05-14 20:39:17,295 - config - INFO - Starting MCP server via stdio...
2025-05-14 20:39:17,313 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 20:50:26,252 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 20:50:26,252 - config - INFO - Read-only mode: False
2025-05-14 20:50:26,253 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 20:50:28,783 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 20:50:28,783 - config - INFO - Current sys.path: ['C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 20:50:28,794 - config - INFO - Initializing MariaDB_Server...
2025-05-14 20:50:28,800 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-14 20:50:28,812 - config - INFO - Connection pool initialized successfully.
2025-05-14 20:50:28,818 - config - INFO - Registered MCP tools explicitly.
2025-05-14 20:50:28,818 - config - INFO - Starting MCP server via stdio...
2025-05-14 20:50:28,834 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 20:50:28,836 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 20:50:28,837 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-14 20:50:28,857 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-14 20:51:27,276 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 20:51:27,277 - config - INFO - Read-only mode: False
2025-05-14 20:51:27,278 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 20:51:28,937 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 20:51:28,937 - config - INFO - Current sys.path: ['C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 20:51:28,954 - config - INFO - Initializing MariaDB_Server...
2025-05-14 20:51:28,972 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-14 20:51:28,972 - config - INFO - Connection pool initialized successfully.
2025-05-14 20:51:28,989 - config - INFO - Registered MCP tools explicitly.
2025-05-14 20:51:28,989 - config - INFO - Starting MCP server via stdio...
2025-05-14 20:51:28,997 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 20:52:10,266 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 20:52:10,268 - config - ERROR - Unknown dimension for Gemini model ''. Known: ['text-embedding-004']
2025-05-14 20:52:15,365 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 20:52:15,366 - config - ERROR - Unknown dimension for Gemini model 'gemini-pro'. Known: ['text-embedding-004']
2025-05-14 20:52:21,953 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 20:52:21,955 - config - ERROR - Unknown dimension for Gemini model ''. Known: ['text-embedding-004']
2025-05-14 20:52:31,259 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-14 20:52:38,363 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 20:52:38,364 - config - INFO - TOOL START: create_database called for database: 'test_db'
2025-05-14 20:52:38,364 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-14 20:52:38,366 - config - INFO - Switching database context from 'chinook' to 'information_schema'
2025-05-14 20:52:38,368 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 20:52:38,368 - config - ERROR - Unknown dimension for Gemini model ''. Known: ['text-embedding-004']
2025-05-14 20:52:38,370 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-14 20:52:38,370 - config - INFO - TOOL END: create_database. Database 'test_db' already exists.
2025-05-14 21:01:12,909 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:01:12,909 - config - INFO - Read-only mode: False
2025-05-14 21:01:12,909 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:01:16,575 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:01:16,576 - config - INFO - Current sys.path: ['C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 21:01:16,589 - config - INFO - Initializing MariaDB_Server...
2025-05-14 21:01:16,601 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-14 21:01:16,613 - config - INFO - Connection pool initialized successfully.
2025-05-14 21:01:16,621 - config - INFO - Registered MCP tools explicitly.
2025-05-14 21:01:16,622 - config - INFO - Starting MCP server via stdio...
2025-05-14 21:01:16,648 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 21:01:16,650 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 21:01:16,652 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-14 21:01:16,669 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-14 21:01:57,758 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:01:57,766 - config - INFO - Read-only mode: False
2025-05-14 21:01:57,766 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:02:00,365 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:02:00,366 - config - INFO - Current sys.path: ['C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 21:02:00,413 - config - INFO - Initializing MariaDB_Server...
2025-05-14 21:02:00,420 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-14 21:02:00,441 - config - INFO - Connection pool initialized successfully.
2025-05-14 21:02:00,457 - config - INFO - Registered MCP tools explicitly.
2025-05-14 21:02:00,457 - config - INFO - Starting MCP server via stdio...
2025-05-14 21:02:00,469 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 21:02:22,363 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 21:02:22,364 - config - ERROR - Unknown dimension for Gemini model ''. Known: ['text-embedding-004']
2025-05-14 21:14:49,265 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:14:49,265 - config - INFO - Read-only mode: False
2025-05-14 21:14:49,266 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:14:52,745 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:14:52,745 - config - INFO - Current sys.path: ['C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Python313\\python313.zip', 'C:\\Python313\\DLLs', 'C:\\Python313\\Lib', 'C:\\Python313', 'C:\\Users\\Mullangi.Vijay\\AppData\\Roaming\\Python\\Python313\\site-packages', 'C:\\Python313\\Lib\\site-packages']
2025-05-14 21:14:52,745 - config - ERROR - Unknown dimension for Gemini model 'non-existent-gemini-model'. Known: ['text-embedding-004']
2025-05-14 21:17:32,348 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:17:32,348 - config - INFO - Read-only mode: False
2025-05-14 21:17:32,349 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:17:34,933 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:17:34,933 - config - INFO - Current sys.path: ['c:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 21:17:34,933 - config - ERROR - Unknown dimension for Gemini model 'non-existent-gemini-model'. Known: ['text-embedding-004']
2025-05-14 21:18:05,200 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:18:05,200 - config - INFO - Read-only mode: False
2025-05-14 21:18:05,200 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:18:07,372 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:18:07,382 - config - INFO - Current sys.path: ['c:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 21:18:07,382 - config - ERROR - Unknown dimension for Gemini model 'non-existent-gemini-model'. Known: ['text-embedding-004']
2025-05-14 21:19:42,537 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:19:42,537 - config - INFO - Read-only mode: False
2025-05-14 21:19:42,537 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:19:44,513 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:19:44,513 - config - INFO - Current sys.path: ['c:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 21:19:44,513 - config - ERROR - Unknown dimension for Gemini model 'non-existent-gemini-model'. Known: ['text-embedding-004']
2025-05-14 21:21:43,322 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:21:43,323 - config - INFO - Read-only mode: False
2025-05-14 21:21:43,323 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:21:45,369 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:21:45,369 - config - INFO - Current sys.path: ['c:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 21:22:50,198 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:22:50,198 - config - INFO - Read-only mode: False
2025-05-14 21:22:50,198 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:22:52,530 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:22:52,530 - config - INFO - Current sys.path: ['c:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 21:23:34,701 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:23:34,701 - config - INFO - Read-only mode: False
2025-05-14 21:23:34,701 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:23:36,730 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:23:36,730 - config - INFO - Current sys.path: ['c:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 21:24:52,831 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:24:52,831 - config - INFO - Read-only mode: False
2025-05-14 21:24:52,831 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:24:54,843 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:24:54,843 - config - INFO - Current sys.path: ['c:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 21:26:11,576 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:26:11,577 - config - INFO - Read-only mode: False
2025-05-14 21:26:11,578 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:26:13,466 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:26:13,466 - config - INFO - Current sys.path: ['c:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 21:27:05,225 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:27:05,226 - config - INFO - Read-only mode: False
2025-05-14 21:27:05,226 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:27:07,188 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:27:07,188 - config - INFO - Current sys.path: ['c:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 21:29:41,919 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:29:41,919 - config - INFO - Read-only mode: False
2025-05-14 21:29:41,920 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:29:44,170 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:29:44,170 - config - INFO - Current sys.path: ['c:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 21:30:33,818 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:30:33,818 - config - INFO - Read-only mode: False
2025-05-14 21:30:33,818 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:30:35,731 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:30:35,732 - config - INFO - Current sys.path: ['c:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 21:31:04,110 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:31:04,110 - config - INFO - Read-only mode: False
2025-05-14 21:31:04,111 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:31:06,043 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:31:06,059 - config - INFO - Current sys.path: ['c:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 21:31:21,726 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:31:21,727 - config - INFO - Read-only mode: False
2025-05-14 21:31:21,728 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:31:23,643 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:31:23,643 - config - INFO - Current sys.path: ['c:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 21:34:35,873 - config - INFO - Selected Embedding Provider: openai
2025-05-14 21:34:35,873 - config - INFO - Read-only mode: False
2025-05-14 21:34:35,874 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:34:37,461 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:34:37,463 - config - INFO - Current sys.path: ['C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\python311.zip', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\DLLs', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11\\Lib', 'C:\\Users\\Mullangi.Vijay\\AppData\\Local\\anaconda3\\envs\\python3dot11', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv', 'C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini\\.venv\\Lib\\site-packages']
2025-05-14 21:34:37,474 - config - INFO - Initializing MariaDB_Server...
2025-05-14 21:34:37,480 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-14 21:34:37,490 - config - INFO - Connection pool initialized successfully.
2025-05-14 21:34:37,495 - config - INFO - Registered MCP tools explicitly.
2025-05-14 21:34:37,496 - config - INFO - Starting MCP server via stdio...
2025-05-14 21:34:37,503 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 21:35:03,126 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 21:35:03,127 - config - ERROR - Unknown dimension for OpenAI model ''. Known: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-14 21:46:05,424 - config - INFO - Selected Embedding Provider: openai
2025-05-14 21:46:05,434 - config - INFO - Read-only mode: False
2025-05-14 21:46:05,435 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:46:08,608 - config - INFO - Successfully imported google.genai
2025-05-14 21:47:27,306 - config - INFO - Selected Embedding Provider: openai
2025-05-14 21:47:27,307 - config - INFO - Read-only mode: False
2025-05-14 21:47:27,307 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:47:29,133 - config - INFO - Successfully imported google.genai
2025-05-14 21:47:29,139 - config - INFO - Initializing MariaDB_Server...
2025-05-14 21:47:29,156 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-14 21:47:29,166 - config - INFO - Connection pool initialized successfully.
2025-05-14 21:47:29,169 - config - INFO - Registered MCP tools explicitly.
2025-05-14 21:47:29,169 - config - INFO - Starting MCP server via stdio...
2025-05-14 21:47:29,180 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 21:49:40,625 - config - INFO - Selected Embedding Provider: openai
2025-05-14 21:49:40,625 - config - INFO - Read-only mode: False
2025-05-14 21:49:40,626 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:49:42,430 - config - INFO - Successfully imported google.genai
2025-05-14 21:49:42,442 - config - INFO - Initializing MariaDB_Server...
2025-05-14 21:49:42,450 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-14 21:49:42,468 - config - INFO - Connection pool initialized successfully.
2025-05-14 21:49:42,479 - config - INFO - Registered MCP tools explicitly.
2025-05-14 21:49:42,479 - config - INFO - Starting MCP server via stdio...
2025-05-14 21:49:42,488 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 21:50:36,110 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 21:50:36,111 - config - ERROR - Unknown dimension for OpenAI model ''. Known: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-14 21:50:41,067 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 21:50:41,069 - config - ERROR - Unknown dimension for OpenAI model 'text-embedding-ada-002'. Known: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-14 21:54:12,932 - config - INFO - Selected Embedding Provider: openai
2025-05-14 21:54:12,932 - config - INFO - Read-only mode: False
2025-05-14 21:54:12,933 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:54:15,516 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:54:15,516 - config - INFO - Current sys.path: ['C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Python313\\python313.zip', 'C:\\Python313\\DLLs', 'C:\\Python313\\Lib', 'C:\\Python313', 'C:\\Users\\Mullangi.Vijay\\AppData\\Roaming\\Python\\Python313\\site-packages', 'C:\\Python313\\Lib\\site-packages']
2025-05-14 21:54:15,518 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-14 21:54:15,977 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-14 21:54:17,792 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-05-14 21:56:21,463 - config - INFO - Selected Embedding Provider: openai
2025-05-14 21:56:21,464 - config - INFO - Read-only mode: False
2025-05-14 21:56:21,464 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:56:23,756 - config - WARNING - Google Generative AI SDK ('google-genai' package) not installed. Gemini provider will not be available. Error: No module named 'google.api_core'
2025-05-14 21:56:23,756 - config - INFO - Current sys.path: ['C:\\Users\\Mullangi.Vijay\\CascadeProjects\\mcp-mariadb-server - Gemini', 'C:\\Python313\\python313.zip', 'C:\\Python313\\DLLs', 'C:\\Python313\\Lib', 'C:\\Python313', 'C:\\Users\\Mullangi.Vijay\\AppData\\Roaming\\Python\\Python313\\site-packages', 'C:\\Python313\\Lib\\site-packages']
2025-05-14 21:56:23,759 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-14 21:56:24,147 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-14 21:56:26,415 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-05-14 21:57:35,468 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 21:57:35,469 - config - INFO - Read-only mode: False
2025-05-14 21:57:35,469 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 21:57:38,490 - config - INFO - Successfully imported google.genai
2025-05-14 21:57:38,490 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 21:57:38,888 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-14 21:57:38,888 - config - ERROR - Unexpected error during embedding with gemini model text-embedding-004: 'Client' object has no attribute 'embed_content'
Traceback (most recent call last):
  File "c:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\embeddings.py", line 228, in embed
    self.gemini_client.embed_content,
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Client' object has no attribute 'embed_content'
2025-05-14 22:03:41,838 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 22:03:41,838 - config - INFO - Read-only mode: False
2025-05-14 22:03:41,838 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 22:03:44,101 - config - INFO - Successfully imported google.genai
2025-05-14 22:03:56,654 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 22:03:56,654 - config - INFO - Read-only mode: False
2025-05-14 22:03:56,654 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 22:03:58,923 - config - INFO - Successfully imported google.genai
2025-05-14 22:03:58,923 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 22:03:59,342 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-14 22:03:59,358 - config - ERROR - Unexpected error during embedding with gemini model text-embedding-004: Models.embed_content() got an unexpected keyword argument 'content'
Traceback (most recent call last):
  File "c:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\embeddings.py", line 227, in embed
    embedding_result = await asyncio.to_thread(
                       ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\threads.py", line 25, in to_thread
    return await loop.run_in_executor(None, func_call)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Models.embed_content() got an unexpected keyword argument 'content'
2025-05-14 22:05:02,118 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 22:05:02,118 - config - INFO - Read-only mode: False
2025-05-14 22:05:02,118 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 22:05:04,369 - config - INFO - Successfully imported google.genai
2025-05-14 22:05:04,369 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 22:05:04,755 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-14 22:05:06,988 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-14 22:05:06,999 - config - ERROR - Unexpected error during embedding with gemini model text-embedding-004: 'EmbedContentResponse' object is not subscriptable
Traceback (most recent call last):
  File "c:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\embeddings.py", line 232, in embed
    embeddings.append(embedding_result["embedding"])
                      ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
TypeError: 'EmbedContentResponse' object is not subscriptable
2025-05-14 22:08:06,141 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 22:08:06,141 - config - INFO - Read-only mode: False
2025-05-14 22:08:06,141 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 22:08:08,618 - config - INFO - Successfully imported google.genai
2025-05-14 22:08:08,622 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 22:08:08,968 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-14 22:08:10,614 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-14 22:09:43,648 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 22:09:43,648 - config - INFO - Read-only mode: False
2025-05-14 22:09:43,648 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 22:09:45,276 - config - INFO - Successfully imported google.genai
2025-05-14 22:09:45,286 - config - INFO - Initializing MariaDB_Server...
2025-05-14 22:09:45,291 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-14 22:09:45,305 - config - INFO - Connection pool initialized successfully.
2025-05-14 22:09:45,310 - config - INFO - Registered MCP tools explicitly.
2025-05-14 22:09:45,310 - config - INFO - Starting MCP server via stdio...
2025-05-14 22:09:45,320 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-14 22:09:59,769 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-14 22:09:59,771 - config - ERROR - Unknown dimension for Gemini model ''. Known: ['text-embedding-004']
2025-05-14 22:13:54,706 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 22:13:54,706 - config - INFO - Read-only mode: False
2025-05-14 22:13:54,706 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 22:13:56,771 - config - INFO - Successfully imported google.genai
2025-05-14 22:13:56,771 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 22:13:57,135 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-14 22:13:59,254 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-14 22:13:59,309 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 22:13:59,621 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-14 22:13:59,622 - config - ERROR - Unknown dimension for Gemini model 'non_existent_model'. Known: ['text-embedding-004']
2025-05-14 22:15:06,546 - config - INFO - Selected Embedding Provider: gemini
2025-05-14 22:15:06,546 - config - INFO - Read-only mode: False
2025-05-14 22:15:06,546 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 22:15:08,721 - config - INFO - Successfully imported google.genai
2025-05-14 22:15:08,721 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 22:15:09,138 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-14 22:15:09,772 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-14 22:15:09,822 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-14 22:15:10,171 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-14 22:15:10,171 - config - ERROR - Unknown dimension for Gemini model 'non_existent_model'. Known: ['text-embedding-004']
2025-05-14 22:15:52,295 - config - INFO - Selected Embedding Provider: openai
2025-05-14 22:15:52,295 - config - INFO - Read-only mode: False
2025-05-14 22:15:52,295 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 22:15:54,921 - config - INFO - Successfully imported google.genai
2025-05-14 22:15:54,921 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-14 22:15:55,286 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-14 22:15:56,700 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-05-14 22:15:56,721 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-14 22:15:57,020 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-14 22:15:57,021 - config - ERROR - Unknown dimension for OpenAI model 'non_existent_model'. Known: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-14 22:16:11,674 - config - INFO - Selected Embedding Provider: openai
2025-05-14 22:16:11,674 - config - INFO - Read-only mode: False
2025-05-14 22:16:11,674 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 22:16:13,649 - config - INFO - Successfully imported google.genai
2025-05-14 22:16:13,649 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-14 22:16:14,094 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-14 22:16:15,770 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-05-14 22:16:15,775 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-14 22:16:16,171 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-14 22:16:16,171 - config - ERROR - Unknown dimension for OpenAI model 'non_existent_model'. Known: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-14 22:18:20,346 - config - INFO - Selected Embedding Provider: openai
2025-05-14 22:18:20,357 - config - INFO - Read-only mode: False
2025-05-14 22:18:20,357 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-14 22:18:22,550 - config - INFO - Successfully imported google.genai
2025-05-14 22:18:22,552 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-14 22:18:23,061 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-14 22:18:23,097 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-14 22:18:23,439 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 08:34:24,055 - config - INFO - Selected Embedding Provider: openai
2025-05-15 08:34:24,056 - config - INFO - Read-only mode: False
2025-05-15 08:34:24,057 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 08:34:30,553 - config - INFO - Successfully imported google.genai
2025-05-15 08:34:30,585 - config - INFO - Initializing MariaDB_Server...
2025-05-15 08:34:30,600 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 08:34:30,647 - config - INFO - Connection pool initialized successfully.
2025-05-15 08:34:30,663 - config - INFO - Registered MCP tools explicitly.
2025-05-15 08:34:30,663 - config - INFO - Starting MCP server via stdio...
2025-05-15 08:34:30,679 - config - CRITICAL - Server execution failed with an unexpected error: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 79, in stdout_writer
    |     await stdout.flush()
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_fileio.py", line 140, in flush
    |     return await to_thread.run_sync(self._fp.flush)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    |     return await get_async_backend().run_sync_in_worker_thread(
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2470, in run_sync_in_worker_thread
    |     return await future
    |            ^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    |     result = context.run(func, *args)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
    | OSError: [Errno 22] Invalid argument
    +------------------------------------
2025-05-15 08:34:30,915 - config - INFO - Closing database connection pool...
2025-05-15 08:34:30,916 - config - INFO - Database connection pool closed.
2025-05-15 08:34:30,931 - config - CRITICAL - Server failed to start or crashed: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 761, in <module>
  |     anyio.run(
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_eventloop.py", line 74, in run
  |     return async_backend.run(func, args, {}, backend_options)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2310, in run
  |     return runner.run(wrapper())
  |            ^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\runners.py", line 118, in run
  |     return self._loop.run_until_complete(task)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\base_events.py", line 653, in run_until_complete
  |     return future.result()
  |            ^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2298, in wrapper
  |     return await func(*args)
  |            ^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 79, in stdout_writer
    |     await stdout.flush()
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_fileio.py", line 140, in flush
    |     return await to_thread.run_sync(self._fp.flush)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    |     return await get_async_backend().run_sync_in_worker_thread(
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2470, in run_sync_in_worker_thread
    |     return await future
    |            ^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    |     result = context.run(func, *args)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
    | OSError: [Errno 22] Invalid argument
    +------------------------------------
2025-05-15 08:34:30,941 - config - INFO - Server exiting with code 1.
2025-05-15 10:03:46,516 - config - INFO - Selected Embedding Provider: openai
2025-05-15 10:03:46,518 - config - INFO - Read-only mode: False
2025-05-15 10:03:46,519 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 10:03:48,664 - config - INFO - Successfully imported google.genai
2025-05-15 10:03:48,680 - config - INFO - Initializing MariaDB_Server...
2025-05-15 10:03:48,687 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 10:03:48,706 - config - INFO - Connection pool initialized successfully.
2025-05-15 10:03:48,714 - config - INFO - Registered MCP tools explicitly.
2025-05-15 10:03:48,715 - config - INFO - Starting MCP server via stdio...
2025-05-15 10:03:48,730 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 10:17:57,630 - config - INFO - Selected Embedding Provider: openai
2025-05-15 10:17:57,630 - config - INFO - Read-only mode: False
2025-05-15 10:17:57,630 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 10:18:00,294 - config - INFO - Successfully imported google.genai
2025-05-15 10:18:00,294 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-15 10:18:01,033 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 10:18:01,095 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-15 10:18:01,550 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 10:22:48,993 - config - INFO - Selected Embedding Provider: openai
2025-05-15 10:22:48,993 - config - INFO - Read-only mode: False
2025-05-15 10:22:48,993 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 10:22:51,104 - config - INFO - Successfully imported google.genai
2025-05-15 10:22:51,104 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-15 10:22:51,510 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 10:22:53,253 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-05-15 10:22:53,321 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-15 10:22:53,633 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 10:22:53,633 - config - ERROR - Unknown dimension for OpenAI model 'non_existent_model'. Known: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 10:25:48,471 - config - INFO - Selected Embedding Provider: openai
2025-05-15 10:25:48,471 - config - INFO - Read-only mode: False
2025-05-15 10:25:48,472 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 10:25:50,463 - config - INFO - Successfully imported google.genai
2025-05-15 10:26:08,309 - config - INFO - Selected Embedding Provider: openai
2025-05-15 10:26:08,310 - config - INFO - Read-only mode: False
2025-05-15 10:26:08,311 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 10:26:10,348 - config - INFO - Successfully imported google.genai
2025-05-15 10:26:10,355 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-15 10:26:10,727 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 10:26:10,727 - config - ERROR - Unknown dimension for OpenAI model 'non_existent_model'. Known: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 10:30:10,848 - config - INFO - Selected Embedding Provider: openai
2025-05-15 10:30:10,848 - config - INFO - Read-only mode: False
2025-05-15 10:30:10,848 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 10:30:13,477 - config - INFO - Successfully imported google.genai
2025-05-15 10:30:13,477 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-15 10:30:13,852 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 10:30:13,852 - config - ERROR - Unknown dimension for OpenAI model 'non_existent_model'. Known: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 10:41:03,336 - config - INFO - Selected Embedding Provider: openai
2025-05-15 10:41:03,336 - config - INFO - Read-only mode: False
2025-05-15 10:41:03,336 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 10:41:05,362 - config - INFO - Successfully imported google.genai
2025-05-15 10:41:05,363 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-15 10:41:05,737 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 10:41:05,737 - config - ERROR - Unknown dimension for OpenAI model 'non_existent_model'. Known: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 10:41:45,587 - config - INFO - Selected Embedding Provider: openai
2025-05-15 10:41:45,587 - config - INFO - Read-only mode: False
2025-05-15 10:41:45,587 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 10:41:47,550 - config - INFO - Successfully imported google.genai
2025-05-15 10:41:47,550 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-15 10:41:47,930 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 10:41:47,933 - config - ERROR - Unknown dimension for OpenAI model 'non_existent_model'. Known: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 10:42:07,831 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 10:42:07,832 - config - INFO - Read-only mode: False
2025-05-15 10:42:07,832 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 10:42:09,963 - config - INFO - Successfully imported google.genai
2025-05-15 10:42:09,965 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-15 10:42:10,337 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-15 10:42:10,339 - config - ERROR - Unknown dimension for Gemini model 'non_existent_model'. Known: ['text-embedding-004']
2025-05-15 10:59:44,823 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 10:59:44,823 - config - INFO - Read-only mode: False
2025-05-15 10:59:44,823 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 10:59:47,416 - config - INFO - Successfully imported google.genai
2025-05-15 10:59:47,416 - config - INFO - Selected Embedding Provider: openai
2025-05-15 10:59:47,416 - config - INFO - Read-only mode: False
2025-05-15 10:59:47,416 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 10:59:47,416 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-15 10:59:47,790 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-15 11:05:15,700 - config - INFO - Selected Embedding Provider: openai
2025-05-15 11:05:15,700 - config - INFO - Read-only mode: False
2025-05-15 11:05:15,701 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:05:17,776 - config - INFO - Successfully imported google.genai
2025-05-15 11:05:17,776 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-15 11:05:18,162 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 11:05:49,318 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 11:05:49,318 - config - INFO - Read-only mode: False
2025-05-15 11:05:49,318 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:05:51,377 - config - INFO - Successfully imported google.genai
2025-05-15 11:05:51,377 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-15 11:05:51,769 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-15 11:08:04,415 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 11:08:04,416 - config - INFO - Read-only mode: False
2025-05-15 11:08:04,417 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:15:36,808 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 11:15:36,809 - config - INFO - Read-only mode: False
2025-05-15 11:15:36,810 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:17:39,463 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 11:17:39,463 - config - INFO - Read-only mode: False
2025-05-15 11:17:39,463 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:19:33,264 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 11:19:33,265 - config - INFO - Read-only mode: False
2025-05-15 11:19:33,266 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:19:36,116 - config - INFO - Successfully imported google.genai
2025-05-15 11:20:52,719 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 11:20:52,719 - config - INFO - Read-only mode: False
2025-05-15 11:20:52,719 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:20:54,685 - config - INFO - Successfully imported google.genai
2025-05-15 11:21:07,127 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 11:21:07,127 - config - INFO - Read-only mode: False
2025-05-15 11:21:07,127 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:21:09,143 - config - INFO - Successfully imported google.genai
2025-05-15 11:23:16,490 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 11:23:16,490 - config - INFO - Read-only mode: False
2025-05-15 11:23:16,491 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:23:18,651 - config - INFO - Successfully imported google.genai
2025-05-15 11:23:51,920 - config - INFO - Selected Embedding Provider: openai
2025-05-15 11:23:51,921 - config - INFO - Read-only mode: False
2025-05-15 11:23:51,922 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:23:53,929 - config - INFO - Successfully imported google.genai
2025-05-15 11:27:31,285 - config - INFO - Selected Embedding Provider: openai
2025-05-15 11:27:31,285 - config - INFO - Read-only mode: False
2025-05-15 11:27:31,285 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:27:33,391 - config - INFO - Successfully imported google.genai
2025-05-15 11:27:33,391 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-15 11:27:33,759 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 11:29:26,704 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 11:29:26,704 - config - INFO - Read-only mode: False
2025-05-15 11:29:26,704 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:29:29,567 - config - INFO - Successfully imported google.genai
2025-05-15 11:29:29,567 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-15 11:29:30,005 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-15 11:29:59,419 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 11:29:59,420 - config - INFO - Read-only mode: False
2025-05-15 11:29:59,420 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:30:01,398 - config - INFO - Successfully imported google.genai
2025-05-15 11:30:01,398 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-15 11:30:01,762 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-15 11:33:53,409 - config - INFO - Selected Embedding Provider: openai
2025-05-15 11:33:53,409 - config - INFO - Read-only mode: False
2025-05-15 11:33:53,410 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:33:55,389 - config - INFO - Successfully imported google.genai
2025-05-15 11:33:55,390 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-15 11:33:55,762 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 11:35:05,277 - config - INFO - Selected Embedding Provider: openai
2025-05-15 11:35:05,277 - config - INFO - Read-only mode: False
2025-05-15 11:35:05,277 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:35:07,776 - config - INFO - Successfully imported google.genai
2025-05-15 11:35:07,777 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-15 11:35:08,184 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 11:35:08,189 - config - INFO - Initializing MariaDB_Server...
2025-05-15 11:35:08,189 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 11:35:08,211 - config - INFO - Connection pool initialized successfully.
2025-05-15 11:35:08,216 - config - INFO - Registered MCP tools explicitly.
2025-05-15 11:35:08,216 - config - INFO - Starting MCP server via stdio...
2025-05-15 11:35:08,230 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 11:35:08,232 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 11:35:08,234 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-15 11:35:08,245 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-15 11:36:08,273 - config - INFO - Selected Embedding Provider: openai
2025-05-15 11:36:08,273 - config - INFO - Read-only mode: False
2025-05-15 11:36:08,275 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:36:11,541 - config - INFO - Successfully imported google.genai
2025-05-15 11:36:11,541 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-15 11:36:12,348 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 11:36:12,364 - config - INFO - Initializing MariaDB_Server...
2025-05-15 11:36:12,364 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 11:36:12,381 - config - INFO - Connection pool initialized successfully.
2025-05-15 11:36:12,396 - config - INFO - Registered MCP tools explicitly.
2025-05-15 11:36:12,396 - config - INFO - Starting MCP server via stdio...
2025-05-15 11:36:12,409 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 11:37:18,942 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 11:37:18,993 - config - INFO - TOOL START: list_vector_stores called for database: 'test'
2025-05-15 11:37:18,993 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-15 11:37:19,001 - config - INFO - Switching database context from 'chinook' to 'information_schema'
2025-05-15 11:37:19,006 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 11:37:19,007 - config - WARNING - Database 'test' does not exist. Cannot list vector stores.
2025-05-15 11:37:55,214 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 11:37:55,215 - config - INFO - TOOL START: list_vector_stores called for database: 'test_db'
2025-05-15 11:37:55,215 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-15 11:37:55,219 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-15 11:37:55,219 - config - INFO - Executing query (DB: information_schema): 
        SELECT DISTINCT T1.TABLE_NAME
        FROM information_schema.COLUMNS AS T1
        INNER J...
2025-05-15 11:37:55,432 - config - INFO - Query executed successfully, 2 rows returned.
2025-05-15 11:37:55,432 - config - INFO - Found 2 vector store(s) in database 'test_db': ['test_vdb_tbl', 'test_vector_store']
2025-05-15 11:37:55,432 - config - INFO - TOOL END: list_vector_stores completed for database 'test_db'.
2025-05-15 11:40:06,633 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 11:40:06,634 - config - INFO - TOOL START: delete_vector_store called for: 'test_db.test_vdb_tbl'
2025-05-15 11:40:06,635 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-15 11:40:06,638 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-15 11:40:06,639 - config - INFO - Executing query (DB: information_schema): SELECT TABLE_NAME FROM information_schema.TABLES WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s...
2025-05-15 11:40:06,640 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-15 11:40:06,641 - config - INFO - Executing query (DB: information_schema): 
        SELECT COUNT(T1.TABLE_NAME) AS vector_store_count
        FROM information_schema.COLUMNS A...
2025-05-15 11:40:06,883 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-15 11:40:06,883 - config - INFO - Executing query (DB: test_db): DROP TABLE IF EXISTS `test_vdb_tbl`;...
2025-05-15 11:40:06,884 - config - INFO - Switching database context from 'information_schema' to 'test_db'
2025-05-15 11:40:06,914 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 11:49:24,325 - config - INFO - TOOL END: delete_vector_store. Vector store 'test_vdb_tbl' deleted successfully from database 'test_db'.
2025-05-15 11:49:24,334 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 11:49:24,335 - config - INFO - TOOL START: list_tables called. database_name=test_db
2025-05-15 11:49:24,336 - config - INFO - Executing query (DB: test_db): SHOW TABLES...
2025-05-15 11:49:24,336 - config - CRITICAL - Server execution failed with an unexpected error: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 79, in stdout_writer
    |     await stdout.flush()
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_fileio.py", line 140, in flush
    |     return await to_thread.run_sync(self._fp.flush)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    |     return await get_async_backend().run_sync_in_worker_thread(
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2470, in run_sync_in_worker_thread
    |     return await future
    |            ^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    |     result = context.run(func, *args)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
    | OSError: [Errno 22] Invalid argument
    +------------------------------------
2025-05-15 11:49:24,555 - config - INFO - Closing database connection pool...
2025-05-15 11:49:24,561 - config - INFO - Database connection pool closed.
2025-05-15 11:49:24,565 - config - CRITICAL - Server failed to start or crashed: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 761, in <module>
  |     anyio.run(
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_eventloop.py", line 74, in run
  |     return async_backend.run(func, args, {}, backend_options)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2310, in run
  |     return runner.run(wrapper())
  |            ^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\runners.py", line 118, in run
  |     return self._loop.run_until_complete(task)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\base_events.py", line 653, in run_until_complete
  |     return future.result()
  |            ^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2298, in wrapper
  |     return await func(*args)
  |            ^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 79, in stdout_writer
    |     await stdout.flush()
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_fileio.py", line 140, in flush
    |     return await to_thread.run_sync(self._fp.flush)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    |     return await get_async_backend().run_sync_in_worker_thread(
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2470, in run_sync_in_worker_thread
    |     return await future
    |            ^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    |     result = context.run(func, *args)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
    | OSError: [Errno 22] Invalid argument
    +------------------------------------
2025-05-15 11:49:24,652 - config - INFO - Server exiting with code 1.
2025-05-15 11:50:31,072 - config - INFO - Selected Embedding Provider: openai
2025-05-15 11:50:31,072 - config - INFO - Read-only mode: False
2025-05-15 11:50:31,072 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:50:34,541 - config - INFO - Successfully imported google.genai
2025-05-15 11:50:34,543 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-15 11:50:35,651 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 11:50:35,679 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 11:50:35,696 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 11:50:35,712 - config - INFO - Connection pool initialized successfully.
2025-05-15 11:50:35,727 - config - INFO - Registered MCP tools explicitly.
2025-05-15 11:50:35,727 - config - INFO - Starting MCP server via stdio...
2025-05-15 11:50:35,743 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 11:51:16,479 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 11:51:16,480 - config - INFO - TOOL START: list_tables called. database_name=test_db
2025-05-15 11:51:16,481 - config - INFO - Executing query (DB: test_db): SHOW TABLES...
2025-05-15 11:51:16,482 - config - INFO - Switching database context from 'chinook' to 'test_db'
2025-05-15 11:51:16,484 - config - INFO - Query executed successfully, 3 rows returned.
2025-05-15 11:51:16,485 - config - INFO - TOOL END: list_tables completed. Tables found: 3.
2025-05-15 11:51:51,217 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 11:59:11,746 - config - INFO - Selected Embedding Provider: openai
2025-05-15 11:59:11,746 - config - INFO - Read-only mode: False
2025-05-15 11:59:11,746 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 11:59:14,587 - config - INFO - Successfully imported google.genai
2025-05-15 11:59:14,596 - config - INFO - Initializing EmbeddingService with provider: openai
2025-05-15 11:59:15,027 - config - INFO - OpenAI client initialized. Default model: text-embedding-3-small. Allowed: ['text-embedding-3-small', 'text-embedding-3-large']
2025-05-15 11:59:15,036 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 11:59:15,046 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 11:59:15,055 - config - INFO - Connection pool initialized successfully.
2025-05-15 11:59:15,059 - config - INFO - Registered MCP tools explicitly.
2025-05-15 11:59:15,059 - config - INFO - Starting MCP server via stdio...
2025-05-15 11:59:15,069 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 11:59:27,935 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 11:59:27,936 - config - INFO - TOOL START: create_vector_store called. DB: 'test_db', Store: 'test_vdb_tbl', Model: 'None', Embedding_Length: 1536, Distance_Requested: 'None'
2025-05-15 11:59:27,936 - config - INFO - Distance function not provided, defaulting to 'COSINE'.
2025-05-15 11:59:27,937 - config - INFO - Using SQL distance function: 'COSINE'.
2025-05-15 11:59:27,937 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-15 11:59:27,938 - config - INFO - Switching database context from 'chinook' to 'information_schema'
2025-05-15 11:59:27,940 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-15 11:59:27,940 - config - INFO - Executing query (DB: information_schema): SELECT TABLE_NAME FROM information_schema.TABLES WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s...
2025-05-15 11:59:27,942 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 11:59:27,942 - config - INFO - Executing query (DB: test_db): 
        CREATE TABLE IF NOT EXISTS `test_vdb_tbl` (
            id VARCHAR(36) NOT NULL DEFAULT UUI...
2025-05-15 11:59:27,943 - config - INFO - Switching database context from 'information_schema' to 'test_db'
2025-05-15 11:59:28,022 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 11:59:28,022 - config - INFO - TOOL END: create_vector_store completed. Vector store 'test_vdb_tbl' created successfully in database 'test_db' with COSINE distance.
2025-05-15 12:00:38,810 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 12:00:40,584 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings "HTTP/1.1 200 OK"
2025-05-15 12:00:40,809 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 12:00:40,822 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 12:00:40,837 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 12:00:40,837 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 12:00:40,837 - config - INFO - Inserted 2 documents into test_db.test_vdb_tbl (errors: 0)
2025-05-15 12:01:24,090 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 12:01:24,091 - config - INFO - TOOL START: execute_sql called. database_name=test_db, sql_query=SELECT id, document, metadata FROM test_vdb_tbl LIMIT 5;, parameters=None
2025-05-15 12:01:24,092 - config - INFO - Executing query (DB: test_db): SELECT id, document, metadata FROM test_vdb_tbl LIMIT 5;...
2025-05-15 12:03:45,850 - config - INFO - Query executed successfully, 2 rows returned.
2025-05-15 12:03:45,851 - config - INFO - TOOL END: execute_sql completed. Rows returned: 2.
2025-05-15 12:04:33,442 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 12:04:33,442 - config - INFO - Read-only mode: False
2025-05-15 12:04:33,444 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 12:04:36,511 - config - INFO - Successfully imported google.genai
2025-05-15 12:04:36,512 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-15 12:04:37,060 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-15 12:04:37,070 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 12:04:37,075 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 12:04:37,086 - config - INFO - Connection pool initialized successfully.
2025-05-15 12:04:37,095 - config - INFO - Registered MCP tools explicitly.
2025-05-15 12:04:37,096 - config - INFO - Starting MCP server via stdio...
2025-05-15 12:04:37,103 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 12:06:57,987 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 12:06:57,988 - config - INFO - TOOL START: list_tables called. database_name=test_db
2025-05-15 12:06:57,989 - config - INFO - Executing query (DB: test_db): SHOW TABLES...
2025-05-15 12:06:57,991 - config - INFO - Switching database context from 'chinook' to 'test_db'
2025-05-15 12:06:57,993 - config - INFO - Query executed successfully, 4 rows returned.
2025-05-15 12:06:57,994 - config - INFO - TOOL END: list_tables completed. Tables found: 4.
2025-05-15 12:07:32,388 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 12:07:32,389 - config - INFO - TOOL START: execute_sql called. database_name=test_db, sql_query=DROP TABLE IF EXISTS test_vdb_tbl;, parameters=None
2025-05-15 12:07:32,389 - config - INFO - Executing query (DB: test_db): DROP TABLE IF EXISTS test_vdb_tbl;...
2025-05-15 12:10:38,940 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 12:10:38,941 - config - INFO - TOOL START: delete_vector_store called for: 'test_db.test_vdb_tbl'
2025-05-15 12:10:38,942 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-15 12:10:38,946 - config - INFO - Switching database context from 'chinook' to 'information_schema'
2025-05-15 12:10:38,946 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-15 12:10:38,946 - config - INFO - Executing query (DB: information_schema): SELECT TABLE_NAME FROM information_schema.TABLES WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s...
2025-05-15 12:10:38,952 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-15 12:10:38,953 - config - INFO - Executing query (DB: information_schema): 
        SELECT COUNT(T1.TABLE_NAME) AS vector_store_count
        FROM information_schema.COLUMNS A...
2025-05-15 12:10:39,171 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-15 12:10:39,171 - config - INFO - Executing query (DB: test_db): DROP TABLE IF EXISTS `test_vdb_tbl`;...
2025-05-15 12:10:39,171 - config - INFO - Switching database context from 'information_schema' to 'test_db'
2025-05-15 12:11:48,048 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 12:11:48,049 - config - INFO - Read-only mode: False
2025-05-15 12:11:48,049 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 12:11:50,304 - config - INFO - Successfully imported google.genai
2025-05-15 12:11:50,304 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-15 12:11:50,786 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-15 12:11:50,797 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 12:11:50,797 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 12:11:50,812 - config - INFO - Connection pool initialized successfully.
2025-05-15 12:11:50,812 - config - INFO - Registered MCP tools explicitly.
2025-05-15 12:11:50,812 - config - INFO - Starting MCP server via stdio...
2025-05-15 12:11:50,834 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 12:12:49,956 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 12:12:49,957 - config - INFO - TOOL START: list_tables called. database_name=test
2025-05-15 12:12:49,958 - config - INFO - Executing query (DB: test): SHOW TABLES...
2025-05-15 12:12:49,959 - config - INFO - Switching database context from 'chinook' to 'test'
2025-05-15 12:12:50,015 - config - ERROR - Database error executing query (Connection: acquired): (1049, "Unknown database 'test'")
Traceback (most recent call last):
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 136, in _execute_query
    await cursor.execute(f"USE `{database}`")
  File "asyncmy\\cursors.pyx", line 179, in execute
  File "asyncmy\\cursors.pyx", line 364, in _query
  File "asyncmy\\connection.pyx", line 496, in query
  File "asyncmy\\connection.pyx", line 684, in _read_query_result
  File "asyncmy\\connection.pyx", line 1071, in read
  File "asyncmy\\connection.pyx", line 646, in read_packet
  File "asyncmy\\protocol.pyx", line 190, in asyncmy.protocol.MysqlPacket.raise_for_error
  File "asyncmy\\protocol.pyx", line 194, in asyncmy.protocol.MysqlPacket.raise_for_error
  File "asyncmy\\errors.pyx", line 128, in asyncmy.errors.raise_mysql_exception
  File "asyncmy\\errors.pyx", line 137, in asyncmy.errors.raise_mysql_exception
asyncmy.errors.OperationalError: (1049, "Unknown database 'test'")
2025-05-15 12:12:50,017 - config - ERROR - TOOL ERROR: list_tables failed for database_name=test: Database error: (1049, "Unknown database 'test'")
Traceback (most recent call last):
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 136, in _execute_query
    await cursor.execute(f"USE `{database}`")
  File "asyncmy\\cursors.pyx", line 179, in execute
  File "asyncmy\\cursors.pyx", line 364, in _query
  File "asyncmy\\connection.pyx", line 496, in query
  File "asyncmy\\connection.pyx", line 684, in _read_query_result
  File "asyncmy\\connection.pyx", line 1071, in read
  File "asyncmy\\connection.pyx", line 646, in read_packet
  File "asyncmy\\protocol.pyx", line 190, in asyncmy.protocol.MysqlPacket.raise_for_error
  File "asyncmy\\protocol.pyx", line 194, in asyncmy.protocol.MysqlPacket.raise_for_error
  File "asyncmy\\errors.pyx", line 128, in asyncmy.errors.raise_mysql_exception
  File "asyncmy\\errors.pyx", line 137, in asyncmy.errors.raise_mysql_exception
asyncmy.errors.OperationalError: (1049, "Unknown database 'test'")

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 258, in list_tables
    results = await self._execute_query(sql, database=database_name)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 146, in _execute_query
    raise RuntimeError(f"Database error: {e}") from e
RuntimeError: Database error: (1049, "Unknown database 'test'")
2025-05-15 12:15:15,884 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 12:15:15,885 - config - INFO - TOOL START: list_databases called.
2025-05-15 12:15:15,886 - config - INFO - Executing query (DB: Chinook): SHOW DATABASES...
2025-05-15 12:15:15,888 - config - CRITICAL - Server execution failed with an unexpected error: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 79, in stdout_writer
    |     await stdout.flush()
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_fileio.py", line 140, in flush
    |     return await to_thread.run_sync(self._fp.flush)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    |     return await get_async_backend().run_sync_in_worker_thread(
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2470, in run_sync_in_worker_thread
    |     return await future
    |            ^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    |     result = context.run(func, *args)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
    | OSError: [Errno 22] Invalid argument
    +------------------------------------
2025-05-15 12:15:16,015 - config - INFO - Closing database connection pool...
2025-05-15 12:15:16,016 - config - INFO - Database connection pool closed.
2025-05-15 12:15:16,018 - config - CRITICAL - Server failed to start or crashed: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 761, in <module>
  |     anyio.run(
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_eventloop.py", line 74, in run
  |     return async_backend.run(func, args, {}, backend_options)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2310, in run
  |     return runner.run(wrapper())
  |            ^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\runners.py", line 118, in run
  |     return self._loop.run_until_complete(task)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\base_events.py", line 653, in run_until_complete
  |     return future.result()
  |            ^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2298, in wrapper
  |     return await func(*args)
  |            ^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 79, in stdout_writer
    |     await stdout.flush()
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_fileio.py", line 140, in flush
    |     return await to_thread.run_sync(self._fp.flush)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    |     return await get_async_backend().run_sync_in_worker_thread(
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2470, in run_sync_in_worker_thread
    |     return await future
    |            ^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    |     result = context.run(func, *args)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
    | OSError: [Errno 22] Invalid argument
    +------------------------------------
2025-05-15 12:15:16,080 - config - INFO - Server exiting with code 1.
2025-05-15 12:15:26,797 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 12:15:26,797 - config - INFO - Read-only mode: False
2025-05-15 12:15:26,797 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 12:15:30,403 - config - INFO - Successfully imported google.genai
2025-05-15 12:15:30,403 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-15 12:15:30,969 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-15 12:15:30,984 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 12:15:31,000 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 12:15:31,000 - config - INFO - Connection pool initialized successfully.
2025-05-15 12:15:31,016 - config - INFO - Registered MCP tools explicitly.
2025-05-15 12:15:31,016 - config - INFO - Starting MCP server via stdio...
2025-05-15 12:15:31,063 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 12:15:31,078 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 12:15:31,080 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-15 12:15:31,110 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-15 12:25:31,127 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-15 12:27:08,232 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 12:27:08,233 - config - INFO - TOOL END: execute_sql completed. Rows returned: 0.
2025-05-15 12:27:08,235 - config - CRITICAL - Server execution failed with an unexpected error: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Exception Group Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 86, in stdio_server
    |     yield read_stream, write_stream
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 812, in run_stdio_async
    |     await self._mcp_server.run(
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 483, in run
    |     async with AsyncExitStack() as stack:
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 745, in __aexit__
    |     raise exc_details[1]
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 728, in __aexit__
    |     cb_suppress = await cb(*exc_details)
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 209, in __aexit__
    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
    |     raise BaseExceptionGroup(
    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
    +-+---------------- 1 ----------------
      | Exception Group Traceback (most recent call last):
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 489, in run
      |     async with anyio.create_task_group() as tg:
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
      |     raise BaseExceptionGroup(
      | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
      +-+---------------- 1 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 242, in send
        |     self.send_nowait(item)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 211, in send_nowait
        |     raise ClosedResourceError
        | anyio.ClosedResourceError
        +------------------------------------
2025-05-15 12:27:08,288 - config - INFO - Closing database connection pool...
2025-05-15 12:27:08,288 - config - INFO - Database connection pool closed.
2025-05-15 12:27:08,290 - config - CRITICAL - Server failed to start or crashed: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 761, in <module>
  |     anyio.run(
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_eventloop.py", line 74, in run
  |     return async_backend.run(func, args, {}, backend_options)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2310, in run
  |     return runner.run(wrapper())
  |            ^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\runners.py", line 118, in run
  |     return self._loop.run_until_complete(task)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\base_events.py", line 653, in run_until_complete
  |     return future.result()
  |            ^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2298, in wrapper
  |     return await func(*args)
  |            ^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Exception Group Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 86, in stdio_server
    |     yield read_stream, write_stream
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 812, in run_stdio_async
    |     await self._mcp_server.run(
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 483, in run
    |     async with AsyncExitStack() as stack:
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 745, in __aexit__
    |     raise exc_details[1]
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 728, in __aexit__
    |     cb_suppress = await cb(*exc_details)
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 209, in __aexit__
    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
    |     raise BaseExceptionGroup(
    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
    +-+---------------- 1 ----------------
      | Exception Group Traceback (most recent call last):
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 489, in run
      |     async with anyio.create_task_group() as tg:
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
      |     raise BaseExceptionGroup(
      | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
      +-+---------------- 1 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 242, in send
        |     self.send_nowait(item)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 211, in send_nowait
        |     raise ClosedResourceError
        | anyio.ClosedResourceError
        +------------------------------------
2025-05-15 12:27:08,297 - config - INFO - Server exiting with code 1.
2025-05-15 12:29:23,017 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 12:29:23,017 - config - INFO - Read-only mode: False
2025-05-15 12:29:23,018 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 12:29:25,384 - config - INFO - Successfully imported google.genai
2025-05-15 12:29:25,384 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-15 12:29:25,991 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-15 12:29:26,006 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 12:29:26,006 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 12:29:26,033 - config - INFO - Connection pool initialized successfully.
2025-05-15 12:29:26,039 - config - INFO - Registered MCP tools explicitly.
2025-05-15 12:29:26,039 - config - INFO - Starting MCP server via stdio...
2025-05-15 12:29:26,049 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 12:30:00,098 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 12:30:00,100 - config - INFO - TOOL START: create_database called for database: 'test_db'
2025-05-15 12:30:00,101 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-15 12:30:00,103 - config - INFO - Switching database context from 'chinook' to 'information_schema'
2025-05-15 12:30:00,109 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 12:30:00,113 - config - INFO - Executing query (DB: Chinook): CREATE DATABASE IF NOT EXISTS `test_db`;...
2025-05-15 12:30:00,116 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 12:30:00,116 - config - INFO - TOOL END: create_database. Database 'test_db' created successfully.
2025-05-15 12:30:38,870 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 12:30:38,870 - config - INFO - TOOL START: create_vector_store called. DB: 'test_db', Store: 'test_vdb_tbl', Model: 'None', Embedding_Length: 768, Distance_Requested: 'None'
2025-05-15 12:30:38,871 - config - INFO - Distance function not provided, defaulting to 'COSINE'.
2025-05-15 12:30:38,871 - config - INFO - Using SQL distance function: 'COSINE'.
2025-05-15 12:30:38,872 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-15 12:30:38,874 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-15 12:30:38,875 - config - INFO - Executing query (DB: information_schema): SELECT TABLE_NAME FROM information_schema.TABLES WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s...
2025-05-15 12:30:38,876 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 12:30:38,877 - config - INFO - Executing query (DB: test_db): 
        CREATE TABLE IF NOT EXISTS `test_vdb_tbl` (
            id VARCHAR(36) NOT NULL DEFAULT UUI...
2025-05-15 12:30:38,878 - config - INFO - Switching database context from 'information_schema' to 'test_db'
2025-05-15 12:30:38,916 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 12:30:38,916 - config - INFO - TOOL END: create_vector_store completed. Vector store 'test_vdb_tbl' created successfully in database 'test_db' with COSINE distance.
2025-05-15 12:32:07,530 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 12:32:08,322 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 12:32:09,583 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 12:32:09,606 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 12:40:17,384 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 12:40:17,394 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 12:40:17,396 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 12:40:17,402 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 12:40:17,403 - config - INFO - Inserted 2 documents into test_db.test_vdb_tbl (errors: 0)
2025-05-15 12:40:17,405 - config - CRITICAL - Server execution failed with an unexpected error: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Exception Group Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 86, in stdio_server
    |     yield read_stream, write_stream
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 812, in run_stdio_async
    |     await self._mcp_server.run(
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 483, in run
    |     async with AsyncExitStack() as stack:
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 745, in __aexit__
    |     raise exc_details[1]
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 728, in __aexit__
    |     cb_suppress = await cb(*exc_details)
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 209, in __aexit__
    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
    |     raise BaseExceptionGroup(
    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
    +-+---------------- 1 ----------------
      | Exception Group Traceback (most recent call last):
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 489, in run
      |     async with anyio.create_task_group() as tg:
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
      |     raise BaseExceptionGroup(
      | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
      +-+---------------- 1 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 242, in send
        |     self.send_nowait(item)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 211, in send_nowait
        |     raise ClosedResourceError
        | anyio.ClosedResourceError
        +------------------------------------
2025-05-15 12:40:17,549 - config - INFO - Closing database connection pool...
2025-05-15 12:40:17,549 - config - INFO - Database connection pool closed.
2025-05-15 12:40:18,103 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 12:40:18,121 - config - CRITICAL - Server failed to start or crashed: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 761, in <module>
  |     anyio.run(
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_eventloop.py", line 74, in run
  |     return async_backend.run(func, args, {}, backend_options)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2310, in run
  |     return runner.run(wrapper())
  |            ^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\runners.py", line 118, in run
  |     return self._loop.run_until_complete(task)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\base_events.py", line 653, in run_until_complete
  |     return future.result()
  |            ^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2298, in wrapper
  |     return await func(*args)
  |            ^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Exception Group Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 86, in stdio_server
    |     yield read_stream, write_stream
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 812, in run_stdio_async
    |     await self._mcp_server.run(
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 483, in run
    |     async with AsyncExitStack() as stack:
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 745, in __aexit__
    |     raise exc_details[1]
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 728, in __aexit__
    |     cb_suppress = await cb(*exc_details)
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 209, in __aexit__
    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
    |     raise BaseExceptionGroup(
    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
    +-+---------------- 1 ----------------
      | Exception Group Traceback (most recent call last):
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 489, in run
      |     async with anyio.create_task_group() as tg:
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
      |     raise BaseExceptionGroup(
      | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
      +-+---------------- 1 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 242, in send
        |     self.send_nowait(item)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 211, in send_nowait
        |     raise ClosedResourceError
        | anyio.ClosedResourceError
        +------------------------------------
2025-05-15 12:40:18,169 - config - INFO - Server exiting with code 1.
2025-05-15 12:50:35,542 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 12:50:35,543 - config - INFO - Read-only mode: False
2025-05-15 12:50:35,543 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 12:50:38,712 - config - INFO - Successfully imported google.genai
2025-05-15 12:50:38,712 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-15 12:50:39,402 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-15 12:50:39,416 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 12:50:39,428 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 12:50:39,441 - config - INFO - Connection pool initialized successfully.
2025-05-15 12:50:39,452 - config - INFO - Registered MCP tools explicitly.
2025-05-15 12:50:39,453 - config - INFO - Starting MCP server via stdio...
2025-05-15 12:50:39,460 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 12:51:03,810 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 12:51:05,845 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 12:51:06,308 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 12:51:06,325 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 12:51:06,327 - config - INFO - Switching database context from 'chinook' to 'test_db'
2025-05-15 12:51:06,332 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 12:51:06,333 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 12:51:06,341 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 12:51:06,342 - config - INFO - Inserted 2 documents into test_db.test_vdb_tbl (errors: 0)
2025-05-15 13:05:21,920 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 13:05:23,040 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 13:05:24,023 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 13:05:24,734 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 13:05:25,705 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 13:05:26,428 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 13:05:27,416 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 13:05:28,135 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 13:05:28,140 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 13:05:28,164 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 13:05:28,165 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 13:05:28,172 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 13:14:15,051 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 13:14:15,065 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 13:14:15,066 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 13:14:15,070 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 13:14:15,074 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 13:14:15,082 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 13:14:15,082 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 13:14:15,092 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 13:14:15,097 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 13:14:15,107 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 13:14:15,107 - config - INFO - Inserted 7 documents into test_db.test_vdb_tbl (errors: 0)
2025-05-15 13:15:02,806 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 13:15:02,807 - config - INFO - Read-only mode: False
2025-05-15 13:15:02,807 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 13:15:05,362 - config - INFO - Successfully imported google.genai
2025-05-15 13:15:05,363 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-15 13:15:06,034 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-15 13:15:06,049 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 13:15:06,053 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 13:15:06,069 - config - INFO - Connection pool initialized successfully.
2025-05-15 13:15:06,081 - config - INFO - Registered MCP tools explicitly.
2025-05-15 13:15:06,081 - config - INFO - Starting MCP server via stdio...
2025-05-15 13:15:06,093 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 13:15:42,077 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 13:15:43,757 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 13:15:44,163 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 13:15:45,264 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 13:15:45,700 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 13:15:46,793 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 13:15:46,822 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 13:15:46,822 - config - INFO - Switching database context from 'chinook' to 'test_db'
2025-05-15 13:15:46,874 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 13:15:46,876 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 13:15:46,885 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 13:15:46,886 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 13:15:46,895 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 13:15:46,896 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 13:15:46,904 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 13:15:46,905 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 13:15:46,909 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 13:15:46,910 - config - INFO - Inserted 5 documents into test_db.test_vdb_tbl (errors: 0)
2025-05-15 13:16:55,987 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 13:16:57,549 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 13:16:57,563 - config - INFO - Executing query (DB: test_db): 
            SELECT 
                document,
                metadata,
                VEC_DISTANC...
2025-05-15 13:20:02,639 - config - INFO - Query executed successfully, 7 rows returned.
2025-05-15 13:20:02,640 - config - INFO - Semantic search in test_db.test_vdb_tbl returned 7 results.
2025-05-15 13:20:02,641 - config - CRITICAL - Server execution failed with an unexpected error: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Exception Group Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 86, in stdio_server
    |     yield read_stream, write_stream
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 812, in run_stdio_async
    |     await self._mcp_server.run(
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 483, in run
    |     async with AsyncExitStack() as stack:
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 745, in __aexit__
    |     raise exc_details[1]
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 728, in __aexit__
    |     cb_suppress = await cb(*exc_details)
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 209, in __aexit__
    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
    |     raise BaseExceptionGroup(
    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
    +-+---------------- 1 ----------------
      | Exception Group Traceback (most recent call last):
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 489, in run
      |     async with anyio.create_task_group() as tg:
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
      |     raise BaseExceptionGroup(
      | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
      +-+---------------- 1 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 242, in send
        |     self.send_nowait(item)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 211, in send_nowait
        |     raise ClosedResourceError
        | anyio.ClosedResourceError
        +------------------------------------
2025-05-15 13:20:02,789 - config - INFO - Closing database connection pool...
2025-05-15 13:20:02,789 - config - INFO - Database connection pool closed.
2025-05-15 13:20:02,789 - config - CRITICAL - Server failed to start or crashed: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 761, in <module>
  |     anyio.run(
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_eventloop.py", line 74, in run
  |     return async_backend.run(func, args, {}, backend_options)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2310, in run
  |     return runner.run(wrapper())
  |            ^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\runners.py", line 118, in run
  |     return self._loop.run_until_complete(task)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\base_events.py", line 653, in run_until_complete
  |     return future.result()
  |            ^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2298, in wrapper
  |     return await func(*args)
  |            ^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Exception Group Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 86, in stdio_server
    |     yield read_stream, write_stream
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 812, in run_stdio_async
    |     await self._mcp_server.run(
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 483, in run
    |     async with AsyncExitStack() as stack:
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 745, in __aexit__
    |     raise exc_details[1]
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 728, in __aexit__
    |     cb_suppress = await cb(*exc_details)
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 209, in __aexit__
    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
    |     raise BaseExceptionGroup(
    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
    +-+---------------- 1 ----------------
      | Exception Group Traceback (most recent call last):
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 489, in run
      |     async with anyio.create_task_group() as tg:
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
      |     raise BaseExceptionGroup(
      | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
      +-+---------------- 1 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 242, in send
        |     self.send_nowait(item)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 211, in send_nowait
        |     raise ClosedResourceError
        | anyio.ClosedResourceError
        +------------------------------------
2025-05-15 13:20:02,862 - config - INFO - Server exiting with code 1.
2025-05-15 13:23:34,617 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 13:23:34,618 - config - INFO - Read-only mode: False
2025-05-15 13:23:34,619 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 13:23:38,506 - config - INFO - Successfully imported google.genai
2025-05-15 13:23:38,507 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-15 13:23:39,649 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-15 13:23:39,677 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 13:23:39,696 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 13:23:39,726 - config - INFO - Connection pool initialized successfully.
2025-05-15 13:23:39,744 - config - INFO - Registered MCP tools explicitly.
2025-05-15 13:23:39,744 - config - INFO - Starting MCP server via stdio...
2025-05-15 13:23:39,774 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 13:27:07,686 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 13:27:09,896 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/text-embedding-004:batchEmbedContents "HTTP/1.1 200 OK"
2025-05-15 13:27:09,911 - config - INFO - Executing query (DB: test_db): 
            SELECT 
                document,
                metadata,
                VEC_DISTANC...
2025-05-15 13:27:09,911 - config - INFO - Switching database context from 'chinook' to 'test_db'
2025-05-15 13:27:09,911 - config - INFO - Query executed successfully, 7 rows returned.
2025-05-15 13:27:09,911 - config - INFO - Semantic search in test_db.test_vdb_tbl returned 7 results.
2025-05-15 15:49:14,401 - config - INFO - Selected Embedding Provider: gemini
2025-05-15 15:49:14,401 - config - INFO - Read-only mode: False
2025-05-15 15:49:14,402 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 15:49:16,214 - config - INFO - Successfully imported google.genai
2025-05-15 15:49:16,214 - config - INFO - Initializing EmbeddingService with provider: gemini
2025-05-15 15:49:16,696 - config - INFO - Gemini client initialized. Default model: text-embedding-004. Allowed: ['text-embedding-004']
2025-05-15 15:49:16,708 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 15:49:16,716 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 15:49:16,727 - config - INFO - Connection pool initialized successfully.
2025-05-15 15:49:16,733 - config - INFO - Registered MCP tools explicitly.
2025-05-15 15:49:16,733 - config - INFO - Starting MCP server via stdio...
2025-05-15 15:49:16,741 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 17:15:51,149 - config - INFO - Selected Embedding Provider: huggingface
2025-05-15 17:15:51,149 - config - INFO - Read-only mode: False
2025-05-15 17:15:51,149 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 17:15:57,028 - config - INFO - Successfully imported google.genai
2025-05-15 17:15:57,029 - config - INFO - Initializing EmbeddingService with provider: huggingface
2025-05-15 17:17:03,727 - config - INFO - Selected Embedding Provider: huggingface
2025-05-15 17:17:03,727 - config - INFO - Read-only mode: False
2025-05-15 17:17:03,727 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 17:17:07,016 - config - INFO - Successfully imported google.genai
2025-05-15 17:17:07,019 - config - INFO - Initializing EmbeddingService with provider: huggingface
2025-05-15 17:17:42,899 - config - INFO - Initializing SentenceTransformer with configured HF_MODEL: intfloat/multilingual-e5-large-instruct
2025-05-15 17:17:42,899 - config - INFO - Initializing SentenceTransformer with configured HF_MODEL: intfloat/multilingual-e5-large-instruct
2025-05-15 17:17:42,904 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-05-15 17:17:42,904 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-large-instruct
2025-05-15 17:17:42,904 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-05-15 17:17:42,904 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-large-instruct
2025-05-15 17:18:06,273 - config - INFO - HuggingFace provider initialized. Default model (from config.HF_MODEL): 'intfloat/multilingual-e5-large-instruct'. Client loaded. Allowed models for override: ['intfloat/multilingual-e5-large-instruct', 'BAAI/bge-m3']
2025-05-15 17:18:06,279 - config - INFO - Dimension for default HF model 'intfloat/multilingual-e5-large-instruct' from client: 1024
2025-05-15 17:18:06,850 - config - INFO - Dimension for default HF model 'intfloat/multilingual-e5-large-instruct' from client: 1024
2025-05-15 17:18:06,857 - config - INFO - Dynamically loading HuggingFace model 'BAAI/bge-m3' for this embed call (different from pre-loaded 'intfloat/multilingual-e5-large-instruct').
2025-05-15 17:18:06,877 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-05-15 17:18:06,878 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-m3
2025-05-15 17:18:08,003 - config - INFO - HuggingFace provider initialized. Default model (from config.HF_MODEL): 'intfloat/multilingual-e5-large-instruct'. Client loaded. Allowed models for override: ['intfloat/multilingual-e5-large-instruct', 'BAAI/bge-m3']
2025-05-15 17:18:08,004 - config - INFO - Dimension for default HF model 'intfloat/multilingual-e5-large-instruct' from client: 1024
2025-05-15 17:18:08,270 - config - INFO - Dimension for default HF model 'intfloat/multilingual-e5-large-instruct' from client: 1024
2025-05-15 17:18:08,270 - config - INFO - Dynamically loading HuggingFace model 'BAAI/bge-m3' for this embed call (different from pre-loaded 'intfloat/multilingual-e5-large-instruct').
2025-05-15 17:18:08,270 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-05-15 17:18:08,270 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-m3
2025-05-15 17:18:19,868 - config - ERROR - Invalid model 'invalid/model-that-does-not-exist' requested for provider 'huggingface'. Allowed: ['intfloat/multilingual-e5-large-instruct', 'BAAI/bge-m3']
2025-05-15 17:18:19,869 - config - ERROR - Embedding requested for empty string, which is not allowed.
2025-05-15 17:18:19,870 - config - ERROR - Unknown dimension for HuggingFace model 'invalid/model-name-for-dimension'. Not in HF_MODEL_DIMENSIONS and not derivable from a non-default model without loading it.
2025-05-15 17:18:21,019 - config - ERROR - Invalid model 'invalid/model-that-does-not-exist' requested for provider 'huggingface'. Allowed: ['intfloat/multilingual-e5-large-instruct', 'BAAI/bge-m3']
2025-05-15 17:18:21,021 - config - ERROR - Embedding requested for empty string, which is not allowed.
2025-05-15 17:18:21,022 - config - ERROR - Unknown dimension for HuggingFace model 'invalid/model-name-for-dimension'. Not in HF_MODEL_DIMENSIONS and not derivable from a non-default model without loading it.
2025-05-15 17:22:15,862 - config - INFO - Selected Embedding Provider: huggingface
2025-05-15 17:22:15,862 - config - INFO - Read-only mode: False
2025-05-15 17:22:15,868 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 17:22:21,311 - config - INFO - Successfully imported google.genai
2025-05-15 17:22:21,311 - config - INFO - Initializing EmbeddingService with provider: huggingface
2025-05-15 17:23:13,156 - config - INFO - Initializing SentenceTransformer with configured HF_MODEL: intfloat/multilingual-e5-large-instruct
2025-05-15 17:23:13,158 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-05-15 17:23:13,158 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-large-instruct
2025-05-15 17:23:26,867 - config - INFO - HuggingFace provider initialized. Default model (from config.HF_MODEL): 'intfloat/multilingual-e5-large-instruct'. Client loaded. Allowed models for override: ['intfloat/multilingual-e5-large-instruct', 'BAAI/bge-m3']
2025-05-15 17:23:26,891 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 17:23:26,894 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 17:23:26,911 - config - INFO - Connection pool initialized successfully.
2025-05-15 17:23:26,911 - config - INFO - Registered MCP tools explicitly.
2025-05-15 17:23:26,911 - config - INFO - Starting MCP server via stdio...
2025-05-15 17:23:26,929 - config - CRITICAL - Server execution failed with an unexpected error: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 79, in stdout_writer
    |     await stdout.flush()
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_fileio.py", line 140, in flush
    |     return await to_thread.run_sync(self._fp.flush)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    |     return await get_async_backend().run_sync_in_worker_thread(
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2470, in run_sync_in_worker_thread
    |     return await future
    |            ^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    |     result = context.run(func, *args)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
    | OSError: [Errno 22] Invalid argument
    +------------------------------------
2025-05-15 17:23:27,061 - config - INFO - Closing database connection pool...
2025-05-15 17:23:27,061 - config - INFO - Database connection pool closed.
2025-05-15 17:23:27,066 - config - CRITICAL - Server failed to start or crashed: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 761, in <module>
  |     anyio.run(
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_eventloop.py", line 74, in run
  |     return async_backend.run(func, args, {}, backend_options)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2310, in run
  |     return runner.run(wrapper())
  |            ^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\runners.py", line 118, in run
  |     return self._loop.run_until_complete(task)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\base_events.py", line 653, in run_until_complete
  |     return future.result()
  |            ^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2298, in wrapper
  |     return await func(*args)
  |            ^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 79, in stdout_writer
    |     await stdout.flush()
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_fileio.py", line 140, in flush
    |     return await to_thread.run_sync(self._fp.flush)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    |     return await get_async_backend().run_sync_in_worker_thread(
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2470, in run_sync_in_worker_thread
    |     return await future
    |            ^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    |     result = context.run(func, *args)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
    | OSError: [Errno 22] Invalid argument
    +------------------------------------
2025-05-15 17:23:27,151 - config - INFO - Server exiting with code 1.
2025-05-15 17:23:49,629 - config - INFO - Selected Embedding Provider: huggingface
2025-05-15 17:23:49,629 - config - INFO - Read-only mode: False
2025-05-15 17:23:49,629 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 17:23:54,305 - config - INFO - Successfully imported google.genai
2025-05-15 17:23:54,307 - config - INFO - Initializing EmbeddingService with provider: huggingface
2025-05-15 17:24:13,612 - config - INFO - Initializing SentenceTransformer with configured HF_MODEL: intfloat/multilingual-e5-large-instruct
2025-05-15 17:24:13,616 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-05-15 17:24:13,618 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-large-instruct
2025-05-15 17:24:25,477 - config - INFO - HuggingFace provider initialized. Default model (from config.HF_MODEL): 'intfloat/multilingual-e5-large-instruct'. Client loaded. Allowed models for override: ['intfloat/multilingual-e5-large-instruct', 'BAAI/bge-m3']
2025-05-15 17:24:25,503 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 17:24:25,516 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 17:24:25,522 - config - INFO - Connection pool initialized successfully.
2025-05-15 17:24:25,537 - config - INFO - Registered MCP tools explicitly.
2025-05-15 17:24:25,538 - config - INFO - Starting MCP server via stdio...
2025-05-15 17:24:25,574 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 17:24:25,578 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 17:24:25,580 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-15 17:24:25,618 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-15 17:28:37,285 - config - INFO - Selected Embedding Provider: huggingface
2025-05-15 17:28:37,286 - config - INFO - Read-only mode: False
2025-05-15 17:28:37,287 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 17:28:41,272 - config - INFO - Successfully imported google.genai
2025-05-15 17:28:41,272 - config - INFO - Initializing EmbeddingService with provider: huggingface
2025-05-15 17:28:56,979 - config - INFO - Initializing SentenceTransformer with configured HF_MODEL: intfloat/multilingual-e5-large-instruct
2025-05-15 17:28:56,984 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-05-15 17:28:56,985 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-large-instruct
2025-05-15 17:29:12,034 - config - INFO - HuggingFace provider initialized. Default model (from config.HF_MODEL): 'intfloat/multilingual-e5-large-instruct'. Client loaded. Allowed models for override: ['intfloat/multilingual-e5-large-instruct', 'BAAI/bge-m3']
2025-05-15 17:29:12,324 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 17:29:12,387 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 17:29:12,403 - config - INFO - Connection pool initialized successfully.
2025-05-15 17:29:12,436 - config - INFO - Registered MCP tools explicitly.
2025-05-15 17:29:12,436 - config - INFO - Starting MCP server via stdio...
2025-05-15 17:29:12,482 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 17:30:11,277 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 17:30:11,279 - config - INFO - TOOL START: create_database called for database: 'test_db'
2025-05-15 17:30:11,280 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-15 17:30:11,286 - config - INFO - Switching database context from 'chinook' to 'information_schema'
2025-05-15 17:30:11,290 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 17:30:11,292 - config - INFO - Executing query (DB: Chinook): CREATE DATABASE IF NOT EXISTS `test_db`;...
2025-05-15 17:30:11,293 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 17:30:11,295 - config - INFO - TOOL END: create_database. Database 'test_db' created successfully.
2025-05-15 17:31:00,308 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 17:31:00,309 - config - INFO - Dimension for default HF model 'intfloat/multilingual-e5-large-instruct' from client: 1024
2025-05-15 17:31:00,310 - config - INFO - TOOL START: create_vector_store called. DB: 'test_db', Store: 'test_vdb_tbl', Model: 'None', Embedding_Length: 1024, Distance_Requested: 'None'
2025-05-15 17:31:00,311 - config - INFO - Distance function not provided, defaulting to 'COSINE'.
2025-05-15 17:31:00,311 - config - INFO - Using SQL distance function: 'COSINE'.
2025-05-15 17:31:00,312 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-15 17:31:00,314 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-15 17:31:00,316 - config - INFO - Executing query (DB: information_schema): SELECT TABLE_NAME FROM information_schema.TABLES WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s...
2025-05-15 17:31:00,317 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 17:31:00,319 - config - INFO - Executing query (DB: test_db): 
        CREATE TABLE IF NOT EXISTS `test_vdb_tbl` (
            id VARCHAR(36) NOT NULL DEFAULT UUI...
2025-05-15 17:31:00,319 - config - INFO - Switching database context from 'information_schema' to 'test_db'
2025-05-15 17:31:00,353 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 17:31:00,354 - config - INFO - TOOL END: create_vector_store completed. Vector store 'test_vdb_tbl' created successfully in database 'test_db' with COSINE distance.
2025-05-15 17:32:33,042 - config - CRITICAL - Server execution failed with an unexpected error: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 79, in stdout_writer
    |     await stdout.flush()
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_fileio.py", line 140, in flush
    |     return await to_thread.run_sync(self._fp.flush)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    |     return await get_async_backend().run_sync_in_worker_thread(
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2470, in run_sync_in_worker_thread
    |     return await future
    |            ^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    |     result = context.run(func, *args)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
    | OSError: [Errno 22] Invalid argument
    +------------------------------------
2025-05-15 17:32:33,046 - config - INFO - Closing database connection pool...
2025-05-15 17:32:33,046 - config - INFO - Database connection pool closed.
2025-05-15 17:32:33,046 - config - CRITICAL - Server failed to start or crashed: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 761, in <module>
  |     anyio.run(
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_eventloop.py", line 74, in run
  |     return async_backend.run(func, args, {}, backend_options)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2310, in run
  |     return runner.run(wrapper())
  |            ^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\runners.py", line 118, in run
  |     return self._loop.run_until_complete(task)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\base_events.py", line 653, in run_until_complete
  |     return future.result()
  |            ^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2298, in wrapper
  |     return await func(*args)
  |            ^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 79, in stdout_writer
    |     await stdout.flush()
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_fileio.py", line 140, in flush
    |     return await to_thread.run_sync(self._fp.flush)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\to_thread.py", line 56, in run_sync
    |     return await get_async_backend().run_sync_in_worker_thread(
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2470, in run_sync_in_worker_thread
    |     return await future
    |            ^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 967, in run
    |     result = context.run(func, *args)
    |              ^^^^^^^^^^^^^^^^^^^^^^^^
    | OSError: [Errno 22] Invalid argument
    +------------------------------------
2025-05-15 17:32:33,062 - config - INFO - Server exiting with code 1.
2025-05-15 17:33:02,600 - config - INFO - Selected Embedding Provider: huggingface
2025-05-15 17:33:02,601 - config - INFO - Read-only mode: False
2025-05-15 17:33:02,602 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 17:33:05,482 - config - INFO - Successfully imported google.genai
2025-05-15 17:33:05,497 - config - INFO - Initializing EmbeddingService with provider: huggingface
2025-05-15 17:33:19,753 - config - INFO - Initializing SentenceTransformer with configured HF_MODEL: intfloat/multilingual-e5-large-instruct
2025-05-15 17:33:19,753 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-05-15 17:33:19,753 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-large-instruct
2025-05-15 17:33:32,268 - config - INFO - HuggingFace provider initialized. Default model (from config.HF_MODEL): 'intfloat/multilingual-e5-large-instruct'. Client loaded. Allowed models for override: ['intfloat/multilingual-e5-large-instruct', 'BAAI/bge-m3']
2025-05-15 17:33:32,282 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 17:33:32,284 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 17:33:32,284 - config - INFO - Connection pool initialized successfully.
2025-05-15 17:33:32,301 - config - INFO - Registered MCP tools explicitly.
2025-05-15 17:33:32,301 - config - INFO - Starting MCP server via stdio...
2025-05-15 17:33:32,310 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 17:36:09,373 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 17:36:09,376 - config - INFO - TOOL START: list_vector_stores called for database: 'test_db'
2025-05-15 17:36:09,377 - config - INFO - Executing query (DB: information_schema): SELECT SCHEMA_NAME FROM information_schema.SCHEMATA WHERE SCHEMA_NAME = %s...
2025-05-15 17:36:09,382 - config - INFO - Switching database context from 'chinook' to 'information_schema'
2025-05-15 17:36:09,384 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-15 17:36:09,385 - config - INFO - Executing query (DB: information_schema): 
        SELECT DISTINCT T1.TABLE_NAME
        FROM information_schema.COLUMNS AS T1
        INNER J...
2025-05-15 17:36:09,672 - config - INFO - Query executed successfully, 1 rows returned.
2025-05-15 17:36:09,672 - config - INFO - Found 1 vector store(s) in database 'test_db': ['test_vdb_tbl']
2025-05-15 17:36:09,672 - config - INFO - TOOL END: list_vector_stores completed for database 'test_db'.
2025-05-15 17:36:14,257 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 17:36:14,792 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 17:36:14,792 - config - INFO - Switching database context from 'information_schema' to 'test_db'
2025-05-15 17:36:14,792 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 17:36:14,808 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 17:36:14,808 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 17:36:14,808 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 17:36:14,822 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 17:36:14,825 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 17:36:14,842 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 17:37:36,179 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 17:37:36,191 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 17:37:36,193 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 17:37:36,200 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 17:37:36,201 - config - INFO - Executing query (DB: test_db): INSERT INTO `test_db`.`test_vdb_tbl` (document, embedding, metadata) VALUES (%s, VEC_FromText(%s), %...
2025-05-15 17:37:36,212 - config - INFO - Query executed successfully, 0 rows returned.
2025-05-15 17:37:36,213 - config - INFO - Inserted 7 documents into test_db.test_vdb_tbl (errors: 0)
2025-05-15 17:37:36,215 - config - CRITICAL - Server execution failed with an unexpected error: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Exception Group Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 86, in stdio_server
    |     yield read_stream, write_stream
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 812, in run_stdio_async
    |     await self._mcp_server.run(
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 483, in run
    |     async with AsyncExitStack() as stack:
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 745, in __aexit__
    |     raise exc_details[1]
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 728, in __aexit__
    |     cb_suppress = await cb(*exc_details)
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 209, in __aexit__
    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
    |     raise BaseExceptionGroup(
    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
    +-+---------------- 1 ----------------
      | Exception Group Traceback (most recent call last):
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 489, in run
      |     async with anyio.create_task_group() as tg:
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
      |     raise BaseExceptionGroup(
      | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
      +-+---------------- 1 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 242, in send
        |     self.send_nowait(item)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 211, in send_nowait
        |     raise ClosedResourceError
        | anyio.ClosedResourceError
        +------------------------------------
2025-05-15 17:37:36,354 - config - INFO - Closing database connection pool...
2025-05-15 17:37:36,354 - config - INFO - Database connection pool closed.
2025-05-15 17:37:36,354 - config - CRITICAL - Server failed to start or crashed: unhandled errors in a TaskGroup (1 sub-exception)
  + Exception Group Traceback (most recent call last):
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 761, in <module>
  |     anyio.run(
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_core\_eventloop.py", line 74, in run
  |     return async_backend.run(func, args, {}, backend_options)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2310, in run
  |     return runner.run(wrapper())
  |            ^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\runners.py", line 118, in run
  |     return self._loop.run_until_complete(task)
  |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\asyncio\base_events.py", line 653, in run_until_complete
  |     return future.result()
  |            ^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 2298, in wrapper
  |     return await func(*args)
  |            ^^^^^^^^^^^^^^^^^
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\server.py", line 732, in run_async_server
  |     await self.mcp.run_async(transport=transport, **transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 283, in run_async
  |     await self.run_stdio_async(**transport_kwargs)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 811, in run_stdio_async
  |     async with stdio_server() as (read_stream, write_stream):
  |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 231, in __aexit__
  |     await self.gen.athrow(typ, value, traceback)
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 83, in stdio_server
  |     async with anyio.create_task_group() as tg:
  |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
  |     raise BaseExceptionGroup(
  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
  +-+---------------- 1 ----------------
    | Exception Group Traceback (most recent call last):
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\stdio.py", line 86, in stdio_server
    |     yield read_stream, write_stream
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\fastmcp\server\server.py", line 812, in run_stdio_async
    |     await self._mcp_server.run(
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 483, in run
    |     async with AsyncExitStack() as stack:
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 745, in __aexit__
    |     raise exc_details[1]
    |   File "C:\Users\Mullangi.Vijay\AppData\Local\anaconda3\envs\python3dot11\Lib\contextlib.py", line 728, in __aexit__
    |     cb_suppress = await cb(*exc_details)
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 209, in __aexit__
    |     return await self._task_group.__aexit__(exc_type, exc_val, exc_tb)
    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
    |     raise BaseExceptionGroup(
    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
    +-+---------------- 1 ----------------
      | Exception Group Traceback (most recent call last):
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 489, in run
      |     async with anyio.create_task_group() as tg:
      |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\_backends\_asyncio.py", line 772, in __aexit__
      |     raise BaseExceptionGroup(
      | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)
      +-+---------------- 1 ----------------
        | Traceback (most recent call last):
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 517, in _handle_message
        |     await self._handle_request(
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\server\lowlevel\server.py", line 563, in _handle_request
        |     await message.respond(response)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 122, in respond
        |     await self._session._send_response(  # type: ignore[reportPrivateUsage]
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\mcp\shared\session.py", line 303, in _send_response
        |     await self._write_stream.send(JSONRPCMessage(jsonrpc_response))
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 242, in send
        |     self.send_nowait(item)
        |   File "C:\Users\Mullangi.Vijay\CascadeProjects\mcp-mariadb-server - Gemini\.venv\Lib\site-packages\anyio\streams\memory.py", line 211, in send_nowait
        |     raise ClosedResourceError
        | anyio.ClosedResourceError
        +------------------------------------
2025-05-15 17:37:36,397 - config - INFO - Server exiting with code 1.
2025-05-15 18:19:25,182 - config - INFO - Selected Embedding Provider: huggingface
2025-05-15 18:19:25,182 - config - INFO - Read-only mode: False
2025-05-15 18:19:25,183 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 18:19:28,139 - config - INFO - Successfully imported google.genai
2025-05-15 18:19:28,140 - config - INFO - Initializing EmbeddingService with provider: huggingface
2025-05-15 18:20:09,417 - config - INFO - Initializing SentenceTransformer with configured HF_MODEL: intfloat/multilingual-e5-large-instruct
2025-05-15 18:20:09,417 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-05-15 18:20:09,417 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-large-instruct
2025-05-15 18:20:25,816 - config - INFO - HuggingFace provider initialized. Default model (from config.HF_MODEL): 'intfloat/multilingual-e5-large-instruct'. Client loaded. Allowed models for override: ['intfloat/multilingual-e5-large-instruct', 'BAAI/bge-m3']
2025-05-15 18:20:25,880 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 18:20:25,906 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 18:20:25,913 - config - INFO - Connection pool initialized successfully.
2025-05-15 18:20:25,926 - config - INFO - Registered MCP tools explicitly.
2025-05-15 18:20:25,927 - config - INFO - Starting MCP server via stdio...
2025-05-15 18:22:36,621 - config - INFO - Selected Embedding Provider: huggingface
2025-05-15 18:22:36,622 - config - INFO - Read-only mode: False
2025-05-15 18:22:36,622 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 18:22:39,602 - config - INFO - Successfully imported google.genai
2025-05-15 18:22:39,603 - config - INFO - Initializing EmbeddingService with provider: huggingface
2025-05-15 18:22:54,187 - config - INFO - Initializing SentenceTransformer with configured HF_MODEL: intfloat/multilingual-e5-large-instruct
2025-05-15 18:22:54,191 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-05-15 18:22:54,192 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-large-instruct
2025-05-15 18:23:11,441 - config - INFO - HuggingFace provider initialized. Default model (from config.HF_MODEL): 'intfloat/multilingual-e5-large-instruct'. Client loaded. Allowed models for override: ['intfloat/multilingual-e5-large-instruct', 'BAAI/bge-m3']
2025-05-15 18:23:11,678 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 18:23:11,728 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 18:23:11,735 - config - INFO - Connection pool initialized successfully.
2025-05-15 18:23:11,755 - config - INFO - Registered MCP tools explicitly.
2025-05-15 18:23:11,756 - config - INFO - Starting MCP server via stdio...
2025-05-15 18:23:11,918 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 18:23:11,923 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 18:23:11,934 - mcp.server.lowlevel.server - INFO - Processing request of type ListResourcesRequest
2025-05-15 18:23:11,990 - mcp.server.lowlevel.server - INFO - Processing request of type ListPromptsRequest
2025-05-15 18:29:29,874 - config - INFO - Selected Embedding Provider: huggingface
2025-05-15 18:29:29,875 - config - INFO - Read-only mode: False
2025-05-15 18:29:29,876 - config - INFO - Logging to console and to file: logs/mcp_server.log (Level: INFO, MaxSize: 10485760B, Backups: 5)
2025-05-15 18:29:34,318 - config - INFO - Successfully imported google.genai
2025-05-15 18:29:34,320 - config - INFO - Initializing EmbeddingService with provider: huggingface
2025-05-15 18:30:10,049 - config - INFO - Initializing SentenceTransformer with configured HF_MODEL: intfloat/multilingual-e5-large-instruct
2025-05-15 18:30:10,052 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2025-05-15 18:30:10,052 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: intfloat/multilingual-e5-large-instruct
2025-05-15 18:30:22,694 - config - INFO - HuggingFace provider initialized. Default model (from config.HF_MODEL): 'intfloat/multilingual-e5-large-instruct'. Client loaded. Allowed models for override: ['intfloat/multilingual-e5-large-instruct', 'BAAI/bge-m3']
2025-05-15 18:30:22,709 - config - INFO - Initializing MariaDB_Ops_Server...
2025-05-15 18:30:22,719 - config - INFO - Creating connection pool for root@localhost:3306/Chinook (max size: 10)
2025-05-15 18:30:22,719 - config - INFO - Connection pool initialized successfully.
2025-05-15 18:30:22,719 - config - INFO - Registered MCP tools explicitly.
2025-05-15 18:30:22,719 - config - INFO - Starting MCP server via stdio...
2025-05-15 18:30:22,743 - mcp.server.lowlevel.server - INFO - Processing request of type ListToolsRequest
2025-05-15 18:30:51,610 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 18:30:51,883 - config - INFO - Executing query (DB: test_db): 
            SELECT 
                document,
                metadata,
                VEC_DISTANC...
2025-05-15 18:30:51,894 - config - INFO - Switching database context from 'chinook' to 'test_db'
2025-05-15 18:30:51,902 - config - INFO - Query executed successfully, 7 rows returned.
2025-05-15 18:30:51,902 - config - INFO - Semantic search in test_db.test_vdb_tbl returned 7 results.
2025-05-15 18:32:02,590 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-05-15 18:32:02,680 - config - INFO - Executing query (DB: test_db): 
            SELECT 
                document,
                metadata,
                VEC_DISTANC...
2025-05-15 18:32:02,695 - config - INFO - Query executed successfully, 7 rows returned.
2025-05-15 18:32:02,695 - config - INFO - Semantic search in test_db.test_vdb_tbl returned 7 results.
